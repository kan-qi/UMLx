library(plyr)
knitr::opts_chunk$set(echo = TRUE)
source("transaction_weights_calibration4.R")
source("comparison_between_size_metrics.R")
library(jsonlite)
library(reshape)
library(tidyverse)
library(fitdistrplus)
library(egg)
library(gridExtra)
cutsAsVec <- function(x) {
ret <- c("Cut Points:")
for (row in rownames(x)) {
cutPoints <- round(x[row, ], digits = 1)
ret <- c(ret, paste(row,":", paste(cutPoints, collapse = ", ")))
}
ret
}
modelData <- read.csv("modelEvaluations-8-30-2.csv")
modelData$Project <- as.character(modelData$Project)
modelData$transaction_file <- as.character(modelData$transaction_file)
effort <- subset(modelData, select=c("Effort"))
transactionFiles <- subset(modelData, select=c("transaction_file"))
rownames(effort) <- modelData$Project
rownames(transactionFiles) <- modelData$Project
combined <- combineData(transactionFiles)
=======
theme_bw(base_size=15)
<<<<<<< HEAD
projects <- rownames(effortData)
View(effort)
#n = 6
effortData = effort
projects <- rownames(effortData)
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numofTrans = nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
View(transactionFiles)
View(transactionFiles)
projects <- rownames(effortData)
print(projects)
projects <- rownames(effortData)
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numofTrans = nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numofTrans = nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
knitr::opts_chunk$set(echo = TRUE)
source("transaction_weights_calibration4.R")
source("comparison_between_size_metrics.R")
library(jsonlite)
library(reshape)
library(tidyverse)
library(fitdistrplus)
library(egg)
library(gridExtra)
library(plyr)
cutsAsVec <- function(x) {
ret <- c("Cut Points:")
for (row in rownames(x)) {
cutPoints <- round(x[row, ], digits = 1)
ret <- c(ret, paste(row,":", paste(cutPoints, collapse = ", ")))
}
ret
}
modelData <- read.csv("modelEvaluations-9-13-1.csv")
modelData$Project <- as.character(modelData$Project)
modelData$transaction_file <- as.character(modelData$transaction_file)
effort <- subset(modelData, select=c("Effort"))
transactionFiles <- subset(modelData, select=c("transaction_file"))
rownames(effort) <- modelData$Project
rownames(transactionFiles) <- modelData$Project
combined <- combineData(transactionFiles)
modelData <- read.csv("modelEvaluations-9-13-1.csv")
modelData$Project <- as.character(modelData$Project)
modelData$transaction_file <- as.character(modelData$transaction_file)
effort <- subset(modelData, select=c("Effort"))
transactionFiles <- subset(modelData, select=c("transaction_file"))
rownames(effort) <- modelData$Project
rownames(transactionFiles) <- modelData$Project
combined <- combineData(transactionFiles)
modelData <- read.csv("modelEvaluations-9-13-1.csv")
modelData$Project <- as.character(modelData$Project)
modelData$transaction_file <- as.character(modelData$transaction_file)
effort <- subset(modelData, select=c("Effort"))
transactionFiles <- subset(modelData, select=c("transaction_file"))
rownames(effort) <- modelData$Project
rownames(transactionFiles) <- modelData$Project
combined <- combineData(transactionFiles)
#n = 6
effortData = effort
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numofTrans = nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
print(numofTrans)
numOfTrans <- 0
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numofTrans = nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
print(numofTrans)
numOfTrans <- 0
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numOfTrans = nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
print(numofTrans)
numOfTrans <- 0
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numOfTrans = nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
print(numOfTrans)
numOfTrans <- 0
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numOfTrans = numOfTrans + nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
print(numOfTrans)
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
View(fileData)
View(fileData)
numOfTrans <- 0
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
print(nrow(fileData))
if(nrow(fileData) < 1){
next
}
numOfTrans = numOfTrans + nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
print(numOfTrans)
numOfTrans <- 0
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
print(fileData)
if(nrow(fileData) < 1){
next
}
numOfTrans = numOfTrans + nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
print(numOfTrans)
numOfTrans <- 0
for (project in projects) {
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
#fileData <- na.omit(fileData)
print(fileData)
if(nrow(fileData) < 1){
next
}
numOfTrans = numOfTrans + nrow(fileData)
#classifiedData <- classify(fileData, cutPoints)
#regressionData[project, ] <- c(classifiedData, effortData[project, "Effort"])
}
print(numOfTrans)
=======
>>>>>>> eeb31ae77ab5fc8e2547c2ca89a88d15da914ad8
>>>>>>> bb9adaac326be892bfca7effc49b75a635e0b119
require(graphics)
require(dgof)
set.seed(1)
x <- rnorm(50)
y <- runif(30)
# Do x and y come from the same distribution?
ks.test(x, y)
# Does x come from a shifted gamma distribution with shape 3 and rate 2?
ks.test(x+2, "pgamma", 3, 2) # two-sided, exact
ks.test(x+2, "pgamma", 3, 2, exact = FALSE)
ks.test(x+2, "pgamma", 3, 2, alternative = "gr")
# test if x is stochastically larger than x2
x2 <- rnorm(50, -1)
plot(ecdf(x), xlim=range(c(x, x2)))
plot(ecdf(x2), add=TRUE, lty="dashed")
t.test(x, x2, alternative="g")
wilcox.test(x, x2, alternative="g")
ks.test(x, x2, alternative="l")
#########################################################
# TBA, JWE new examples added for discrete distributions:
x3 <- sample(1:10, 25, replace=TRUE)
# Using ecdf() to specify a discrete distribution:
ks.test(x3, ecdf(1:10))
# Using step() to specify the same discrete distribution:
myfun <- stepfun(1:10, cumsum(c(0, rep(0.1, 10))))
ks.test(x3, myfun)
# The previous R ks.test() does not correctly calculate the
# test statistic for discrete distributions (gives warning):
# stats::ks.test(c(0, 1), ecdf(c(0, 1)))
# ks.test(c(0, 1), ecdf(c(0, 1)))
# Even when the correct test statistic is given, the
# previous R ks.test() gives conservative p-values:
stats::ks.test(rep(1, 3), ecdf(1:3))
ks.test(rep(1, 3), ecdf(1:3))
ks.test(rep(1, 3), ecdf(1:3), simulate=TRUE, B=10000)
# Do x and y come from the same distribution?
ks.test(x, y)
x <- rnorm(50)
y <- runif(30)
# Do x and y come from the same distribution?
result <- ks.test(x, y)
x <- rnorm(50)
y <- runif(30)
# Do x and y come from the same distribution?
result <- ks.test(x, y)
print(result)
print(result[["p-value"]])
f(30)
# Do x and y come from the same distribution?
result <- ks.test(x, y)
print(result["p-value"])
# Do x and y come from the same distribution?
result <- ks.test(x, y)
View(result)
View(result)
result <- ks.test(x, y)
print(result[['statistic']])
discretize <- function(data, n) {
# Discretizes continuous data into different levels of complexity based on
# quantiles of normal distribution defined by the data.
#
# Args:
#   data: vector of data to discretize
#   n: number of bins to discretize into
#
# Returns:
#   A vector of cut points
#n = 6
#data = combined[, "TD"]
#print(data)
if (n <= 1) {
return(c(-Inf, Inf))
}
quantiles <- seq(1/n, 1 - (1/n), 1/n)
tableValues <- table(data)
#reduce sizes for fitting with gamma curve
#print(as.integer(tableValues/10))
vec <- rep(as.numeric(names(tableValues)), as.integer(tableValues/10))
fit.gamma <- fitdist(vec, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
shape = coefficients(fit.gamma)["shape"]
rate = coefficients(fit.gamma)["rate"]
print(coefficients(fit.gamma))
# testing the goodness of fit.
num_of_samples = length(vec)
y <- rgamma(num_of_samples, shape = shape, rate = rate)
result = ks.test(vec, y)
print("gamma goodness of fit")
print(result)
parametric-test <- parametric-ks-test(vec, shape, rate, result[["statistic"]])
print("parametric test")
print(parametric-test)
cutPoints <- qgamma(quantiles, shape, rate, lower.tail = TRUE)
cutPoints <- c(-Inf, cutPoints, Inf)
#print(cutPoints)
#par(mar = rep(2, 4))
#plot(fit.gamma)
}
parametric-ks-test <- function(dist, shape, rate, ks){
# iterate 10000 samples for ks-statistics
num_of_samples = length(dist)
sample-ks = c()
for(i in 1: 10000){
y <- rgamma(num_of_samples, shape = shape, scale = rate)
result = ks.test(dist, y)
#print("gamma goodness of fit")
#print(result)
sample-ks = c(sample-ks, result[['statistic']])
}
sapply(sample-ks, mean)
tests<-sapply(sample-ks, function(x) {
if(x > ks ){
1
}
else {
0
}
})
sum(tests)
}
parametricKStest <- function(dist, shape, rate, ks){
# iterate 10000 samples for ks-statistics
num_of_samples = length(dist)
sample-ks = c()
for(i in 1: 10000){
y <- rgamma(num_of_samples, shape = shape, scale = rate)
result = ks.test(dist, y)
#print("gamma goodness of fit")
#print(result)
sample-ks = c(sample-ks, result[['statistic']])
}
sapply(sample-ks, mean)
tests<-sapply(sample-ks, function(x) {
if(x > ks ){
1
}
else {
0
}
})
sum(tests)
}
discretize <- function(data, n) {
# Discretizes continuous data into different levels of complexity based on
# quantiles of normal distribution defined by the data.
#
# Args:
#   data: vector of data to discretize
#   n: number of bins to discretize into
#
# Returns:
#   A vector of cut points
#n = 6
#data = combined[, "TD"]
#print(data)
if (n <= 1) {
return(c(-Inf, Inf))
}
quantiles <- seq(1/n, 1 - (1/n), 1/n)
tableValues <- table(data)
#reduce sizes for fitting with gamma curve
#print(as.integer(tableValues/10))
vec <- rep(as.numeric(names(tableValues)), as.integer(tableValues/10))
fit.gamma <- fitdist(vec, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
shape = coefficients(fit.gamma)["shape"]
rate = coefficients(fit.gamma)["rate"]
print(coefficients(fit.gamma))
# testing the goodness of fit.
num_of_samples = length(vec)
y <- rgamma(num_of_samples, shape = shape, rate = rate)
result = ks.test(vec, y)
print("gamma goodness of fit")
print(result)
parametric-test <- pparametricKStest(vec, shape, rate, result[["statistic"]])
print("parametric test")
print(parametric-test)
cutPoints <- qgamma(quantiles, shape, rate, lower.tail = TRUE)
cutPoints <- c(-Inf, cutPoints, Inf)
#print(cutPoints)
#par(mar = rep(2, 4))
#plot(fit.gamma)
}
knitr::opts_chunk$set(echo = TRUE)
source("transaction_weights_calibration4.R")
source("comparison_between_size_metrics.R")
library(jsonlite)
library(reshape)
library(tidyverse)
library(fitdistrplus)
library(egg)
library(gridExtra)
library(plyr)
cutsAsVec <- function(x) {
ret <- c("Cut Points:")
for (row in rownames(x)) {
cutPoints <- round(x[row, ], digits = 1)
ret <- c(ret, paste(row,":", paste(cutPoints, collapse = ", ")))
}
ret
}
modelData <- read.csv("modelEvaluations-9-13-1.csv")
modelData$Project <- as.character(modelData$Project)
modelData$transaction_file <- as.character(modelData$transaction_file)
effort <- subset(modelData, select=c("Effort"))
transactionFiles <- subset(modelData, select=c("transaction_file"))
rownames(effort) <- modelData$Project
rownames(transactionFiles) <- modelData$Project
combined <- combineData(transactionFiles)
