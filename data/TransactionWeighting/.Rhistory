print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numOfTrans = numOfTrans + nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
size <- classifiedData %*% weights
regressionData[project, ] <- c(size, effortData[project, "Effort"])
}
print(numOfTrans)
regressionData <- na.omit(regressionData)
#regressionData <- rbind(regressionData, "Aggregate" = colSums(regressionData))
regressionData <- as.data.frame(regressionData)
print("regressionData")
print(regressionData)
#}
lm.fit <- lm(Effort ~ ., regressionData)
coefficients <- summary(lm.fit)$coefficients
predicts <- as.data.frame(predict(lm.fit, newData = regressionData))
rownames(predicts) <- projects
results = list()
results[["predicts"]] <- predicts
results[["coefficients"]] <- coefficients
results
}
weights <- c(1, 2, 3, 5, 8)
names(weights) <- c("L1", "L2", "L3", "L4", "L5")
cutpoints <- matrix(NA, nrow = 2, ncol = 4)
rownames(cutpoints) <- c("TL", "TD")
cutpoints["TL",] = c(-Inf, 4.1, 6.1, Inf)
cutpoints["TD",] = c(-Inf, 3.1, 6.1, Inf)
results <- prodByLinearRegression(effort1, transactionFiles1, cutpoints, weights)
print(results)
modelData1 <- read.csv("../Resilient Agile/modelEvaluations.csv")
modelData1$Project <- as.character(modelData1$Project)
modelData1$transaction_file <- as.character(modelData1$transaction_file)
effort1 <- subset(modelData1, select=c("Effort"))
rownames(effort1) <- modelData1$Project
transactionFiles1 <- subset(modelData1, select=c("transaction_file"))
rownames(transactionFiles1) <- modelData1$Project
weights <- c(1, 2, 3, 5, 8)
names(weights) <- c("L1", "L2", "L3", "L4", "L5")
cutpoints <- matrix(NA, nrow = 2, ncol = 4)
rownames(cutpoints) <- c("TL", "TD")
cutpoints["TL",] = c(-Inf, 4.1, 6.1, Inf)
cutpoints["TD",] = c(-Inf, 3.1, 6.1, Inf)
results <- prodByLinearRegression(effort1, transactionFiles1, cutpoints, weights)
print(results)
weights <- c(1, 1, 2, 3, 5, 8, 8)
names(weights) <- c("L1", "L2", "L3", "L4", "L5", "L6", "L7")
cutpoints <- matrix(NA, nrow = 3, ncol = 4)
rownames(cutpoints) <- c("TL", "TD", "DETs")
cutpoints[["TL"]] = c(-Inf, 4.1, 6.1, Inf)
weights <- c(1, 1, 2, 3, 5, 8, 8)
names(weights) <- c("L1", "L2", "L3", "L4", "L5", "L6", "L7")
cutpoints <- matrix(NA, nrow = 3, ncol = 4)
rownames(cutpoints) <- c("TL", "TD", "DETs")
cutpoints["TL",] = c(-Inf, 4.1, 6.1, Inf)
cutpoints["TD",] = c(-Inf, 3.1, 6.1, Inf)
cutpoints["DETs",] = c(-Inf, 5.1, 11.1, Inf)
results <- prodByLinearRegression(effort1, transactionFiles1, c())
weights <- c(1, 1, 2, 3, 5, 8, 8)
names(weights) <- c("L1", "L2", "L3", "L4", "L5", "L6", "L7")
cutpoints <- matrix(NA, nrow = 3, ncol = 4)
rownames(cutpoints) <- c("TL", "TD", "DETs")
cutpoints["TL",] = c(-Inf, 4.1, 6.1, Inf)
cutpoints["TD",] = c(-Inf, 3.1, 6.1, Inf)
cutpoints["DETs",] = c(-Inf, 5.1, 11.1, Inf)
results <- prodByLinearRegression(effort1, transactionFiles1, cutpoints, weights)
print(results)
prodByLinearRegression <- function(effortData, transactionFiles, cutPoints, weights){
#effortData <- effort
#transactionFiles <- transactionsFiles
#cutPoints <- cutpoints
#weights <- weights
projects <- rownames(effortData)
regressionData <- matrix(nrow = length(projects), ncol = 2)
rownames(regressionData) <- projects
colnames(regressionData) <- c("size", "Effort")
numOfTrans <- 0
for (project in projects) {
#project <- projects[1]
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numOfTrans = numOfTrans + nrow(fileData)
classifiedData <- classify(fileData, cutPoints)
size <- classifiedData %*% weights
regressionData[project, ] <- c(size, effortData[project, "Effort"])
}
print(numOfTrans)
regressionData <- na.omit(regressionData)
#regressionData <- rbind(regressionData, "Aggregate" = colSums(regressionData))
regressionData <- as.data.frame(regressionData)
print("regressionData")
print(regressionData)
#}
lm.fit <- lm(Effort ~ .-1, regressionData)
coefficients <- summary(lm.fit)$coefficients
predicts <- as.data.frame(predict(lm.fit, newData = regressionData))
rownames(predicts) <- projects
results = list()
results[["predicts"]] <- predicts
results[["coefficients"]] <- coefficients
results
}
weights <- c(1, 1, 2, 3, 5, 8, 8)
names(weights) <- c("L1", "L2", "L3", "L4", "L5", "L6", "L7")
cutpoints <- matrix(NA, nrow = 3, ncol = 4)
rownames(cutpoints) <- c("TL", "TD", "DETs")
cutpoints["TL",] = c(-Inf, 4.1, 6.1, Inf)
cutpoints["TD",] = c(-Inf, 3.1, 6.1, Inf)
cutpoints["DETs",] = c(-Inf, 5.1, 11.1, Inf)
results <- prodByLinearRegression(effort1, transactionFiles1, cutpoints, weights)
print(results)
weights <- c(1, 2, 3, 5, 8)
names(weights) <- c("L1", "L2", "L3", "L4", "L5")
cutpoints <- matrix(NA, nrow = 2, ncol = 4)
rownames(cutpoints) <- c("TL", "TD")
cutpoints["TL",] = c(-Inf, 4.1, 6.1, Inf)
cutpoints["TD",] = c(-Inf, 3.1, 6.1, Inf)
results <- prodByLinearRegression(effort1, transactionFiles1, cutpoints, weights)
print(results)
prodByLinearRegression <- function(effortData, transactionFiles, cutPoints, weights){
#effortData <- effort
#transactionFiles <- transactionsFiles
#cutPoints <- cutpoints
#weights <- weights
projects <- rownames(effortData)
regressionData <- matrix(nrow = length(projects), ncol = 2)
rownames(regressionData) <- projects
colnames(regressionData) <- c("size", "Effort")
numOfTrans <- 0
for (project in projects) {
#project <- projects[1]
filePath <- transactionFiles[project, "transaction_file"]
print(filePath)
if (!file.exists(filePath)) {
print("file doesn't exist")
next
}
fileData <- read.csv(filePath)
fileData <- data.frame(apply(subset(fileData, select = c("TL", "TD", "DETs")), 2, function(x) as.numeric(x)))
fileData <- na.omit(fileData)
if(nrow(fileData) < 1){
next
}
numOfTrans = numOfTrans + nrow(fileData)
if(is.null(cutPoints)){
size = nrow(fileData)
}
else{
classifiedData <- classify(fileData, cutPoints)
size <- classifiedData %*% weights
}
regressionData[project, ] <- c(size, effortData[project, "Effort"])
}
print(numOfTrans)
regressionData <- na.omit(regressionData)
#regressionData <- rbind(regressionData, "Aggregate" = colSums(regressionData))
regressionData <- as.data.frame(regressionData)
print("regressionData")
print(regressionData)
#}
lm.fit <- lm(Effort ~ .-1, regressionData)
coefficients <- summary(lm.fit)$coefficients
predicts <- as.data.frame(predict(lm.fit, newData = regressionData))
rownames(predicts) <- projects
results = list()
results[["predicts"]] <- predicts
results[["coefficients"]] <- coefficients
results
}
#EUCP
weights <- c(1)
names(weights) <- c("L1")
cutpoints <- NULL
results <- prodByLinearRegression(effort1, transactionFiles1, cutpoints, weights)
print(results)
knitr::opts_chunk$set(echo = TRUE)
source("transaction_weights_calibration4.R")
source("comparison_between_size_metrics.R")
library(jsonlite)
library(reshape)
library(tidyverse)
library(fitdistrplus)
library(egg)
library(gridExtra)
library(plyr)
cutsAsVec <- function(x) {
ret <- c("Cut Points:")
for (row in rownames(x)) {
cutPoints <- round(x[row, ], digits = 1)
ret <- c(ret, paste(row,":", paste(cutPoints, collapse = ", ")))
}
ret
}
#Ks parameteric test
parametricKStest(combined[, "TL"])
#Ks parameteric test
parametricKStest(combined[, "TL"])
dist <- combined[, "TL"]
fit.gamma <- fitdist(dist, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
shape = coefficients(fit.gamma)["shape"]
rate = coefficients(fit.gamma)["rate"]
print(coefficients(fit.gamma))
ksResult <- ks.test(dist, "pgamma", shape, rate)
print("gamma goodness of fit")
print(ksResult)
dist <- combined[, "TD"]
#tableValues <- table(dist)
#reduce sizes for fitting with gamma curve
#print(as.integer(tableValues/10))
#dist <- rep(as.numeric(names(tableValues)), as.integer(tableValues/10))
fit.gamma <- fitdist(dist, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
shape = coefficients(fit.gamma)["shape"]
rate = coefficients(fit.gamma)["rate"]
print(coefficients(fit.gamma))
ksResult <- ks.test(dist, "pgamma", shape, rate)
print("gamma goodness of fit")
print(ksResult)
ks = ksResult[['statistic']]
parametricKStest <- function(dist){
#dist <- combined[, "TD"]
#tableValues <- table(dist)
#reduce sizes for fitting with gamma curve
#print(as.integer(tableValues/10))
#dist <- rep(as.numeric(names(tableValues)), as.integer(tableValues/10))
fit.gamma <- fitdist(dist, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
shape = coefficients(fit.gamma)["shape"]
rate = coefficients(fit.gamma)["rate"]
print(coefficients(fit.gamma))
# testing the goodness of fit.
#num_of_samples = length(dist)
#y <- rgamma(num_of_samples, shape = shape, rate = rate)
#result = ks.test(dist, y)
ksResult <- ks.test(dist, "pgamma", shape, rate)
print("gamma goodness of fit")
print(ksResult)
ks = ksResult[['statistic']]
# iterate 10000 samples for ks-statistics
num_of_samples = length(dist)
sample_ks <- c()
runs = 10000
for(i in 1: runs){
run.Sample <- rgamma(num_of_samples, shape = shape, rate = rate)
run.fit.gamma <- fitdist(run.Sample, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
run.shape = coefficients(run.fit.gamma)["shape"]
run.rate = coefficients(run.fit.gamma)["rate"]
result = ks.test(run.Sample, "pgamma", run.shape, run.rate)
#result = ks.test(dist, y)
#print("gamma goodness of fit")
#print(result)
sample_ks = c(sample_ks, result[['statistic']])
}
tests<-sapply(sample_ks, function(x) {
if(x > ks ){
1
}
else {
0
}
})
print(sample_ks)
#print(tests)
parametric_test = sum(tests)/runs
print("parametric test")
print(parametric_test)
parametric_test
}
#Ks parameteric test
parametricKStest(combined[, "TD"])
ist <- combined[, "DETs"]
#tableValues <- table(dist)
#reduce sizes for fitting with gamma curve
#print(as.integer(tableValues/10))
#dist <- rep(as.numeric(names(tableValues)), as.integer(tableValues/10))
fit.gamma <- fitdist(dist, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
shape = coefficients(fit.gamma)["shape"]
rate = coefficients(fit.gamma)["rate"]
print(coefficients(fit.gamma))
# testing the goodness of fit.
#num_of_samples = length(dist)
#y <- rgamma(num_of_samples, shape = shape, rate = rate)
#result = ks.test(dist, y)
ksResult <- ks.test(dist, "pgamma", shape, rate)
print("gamma goodness of fit")
print(ksResult)
ks = ksResult[['statistic']]
# iterate 10000 samples for ks-statistics
num_of_samples = length(dist)
sample_ks <- c()
runs = 10000
for(i in 1: runs){
run.Sample <- rgamma(num_of_samples, shape = shape, rate = rate)
run.fit.gamma <- fitdist(run.Sample, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
run.shape = coefficients(run.fit.gamma)["shape"]
run.rate = coefficients(run.fit.gamma)["rate"]
result = ks.test(run.Sample, "pgamma", run.shape, run.rate)
#result = ks.test(dist, y)
#print("gamma goodness of fit")
#print(result)
sample_ks = c(sample_ks, result[['statistic']])
}
tests<-sapply(sample_ks, function(x) {
if(x > ks ){
1
}
else {
0
}
})
print(sample_ks)
#print(tests)
parametric_test = sum(tests)/runs
print("parametric test")
print(parametric_test)
parametric_test
dist <- combined[, "TD"]
dist <- combined[, "TD"]
#tableValues <- table(dist)
#reduce sizes for fitting with gamma curve
#print(as.integer(tableValues/10))
#dist <- rep(as.numeric(names(tableValues)), as.integer(tableValues/10))
fit.gamma <- fitdist(dist, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
shape = coefficients(fit.gamma)["shape"]
rate = coefficients(fit.gamma)["rate"]
print(coefficients(fit.gamma))
# testing the goodness of fit.
#num_of_samples = length(dist)
#y <- rgamma(num_of_samples, shape = shape, rate = rate)
#result = ks.test(dist, y)
ksResult <- ks.test(dist, "pgamma", shape, rate)
print("gamma goodness of fit")
print(ksResult)
ks = ksResult[['statistic']]
# iterate 10000 samples for ks-statistics
num_of_samples = length(dist)
sample_ks <- c()
runs = 10000
for(i in 1: runs){
run.Sample <- rgamma(num_of_samples, shape = shape, rate = rate)
run.fit.gamma <- fitdist(run.Sample, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
run.shape = coefficients(run.fit.gamma)["shape"]
run.rate = coefficients(run.fit.gamma)["rate"]
result = ks.test(run.Sample, "pgamma", run.shape, run.rate)
#result = ks.test(dist, y)
#print("gamma goodness of fit")
#print(result)
sample_ks = c(sample_ks, result[['statistic']])
}
tests<-sapply(sample_ks, function(x) {
if(x > ks ){
1
}
else {
0
}
})
print(sample_ks)
#print(tests)
parametric_test = sum(tests)/runs
print("parametric test")
print(parametric_test)
parametric_test
modelData <- read.csv("modelEvaluations-9-29.csv")
modelData$Project <- as.character(modelData$Project)
modelData$transaction_file <- as.character(modelData$transaction_file)
effort <- subset(modelData, select=c("Effort"))
transactionFiles <- subset(modelData, select=c("transaction_file"))
rownames(effort) <- modelData$Project
rownames(transactionFiles) <- modelData$Project
combined <- combineData(transactionFiles)
save.image("~/Research Projects/UMLx/data/TransactionWeighting/10-2.RData")
ist <- combined[, "TD"]
x.gam.cut<-cut(dist,breaks=c(0,3,6,9,12,Inf)) ##binning data
table(x.gam.cut) ## binned data table
dist <- combined[, "TD"]
x.gam.cut<-cut(dist,breaks=c(0,3,6,9,12,Inf)) ##binning data
table(x.gam.cut) ## binned data table
fit.gamma <- fitdist(dist, distr = "gamma", method = "mle", lower = c(0, 0))
# Check result
a.est = coefficients(fit.gamma)["shape"]
l.est = coefficients(fit.gamma)["rate"]
num_of_samples = length(dist)
(pgamma(3,shape=a.est,rate=l.est)-pgamma(0,shape=a.est,rate=l.est))*num_of_samples
(pgamma(6,shape=a.est,rate=l.est)-pgamma(3,shape=a.est,rate=l.est))*num_of_samples
(pgamma(9,shape=a.est,rate=l.est)-pgamma(6,shape=a.est,rate=l.est))*num_of_samples
(pgamma(12,shape=a.est,rate=l.est)-pgamma(9,shape=a.est,rate=l.est))*num_of_samples
(pgamma(Inf,shape=a.est,rate=l.est)-pgamma(12,shape=a.est,rate=l.est))*num_of_samples
p1 = (pgamma(3,shape=a.est,rate=l.est)-pgamma(0,shape=a.est,rate=l.est))*num_of_samples
p2 = (pgamma(6,shape=a.est,rate=l.est)-pgamma(3,shape=a.est,rate=l.est))*num_of_samples
p3 = (pgamma(9,shape=a.est,rate=l.est)-pgamma(6,shape=a.est,rate=l.est))*num_of_samples
p4 = (pgamma(12,shape=a.est,rate=l.est)-pgamma(9,shape=a.est,rate=l.est))*num_of_samples
p5 = (pgamma(Inf,shape=a.est,rate=l.est)-pgamma(12,shape=a.est,rate=l.est))*num_of_samples
f.ex<-c(p1, p2, p3, p4, p5) ## expected
f.os<-vector()
for(i in 1:5) f.os[i]<- table(x.gam.cut)[[i]] ## empirical frequencies
X2<-sum(((f.os-f.ex)^2)/f.ex) ## chi-square statistic
gdl<-5-2-1 ## degrees of freedom
1-pchisq(X2,gdl) ## p-value
f.ex<-c(p1, p2, p3, p4, p5) ## expected frequencies vector
f.os<-vector()
for(i in 1:5) f.os[i]<- table(x.gam.cut)[[i]] ## empirical frequencies
dist <- combined[, "TD"]
x.gam.cut<-cut(dist,breaks=c(0,3,6,9,12,Inf)) ##binning data
table(x.gam.cut) ## binned data table
fit.gamma <- fitdist(dist, distr = "gamma", method = "mme", lower = c(0, 0))
# Check result
a.est = coefficients(fit.gamma)["shape"]
l.est = coefficients(fit.gamma)["rate"]
num_of_samples = length(dist)
#x.gam.cut
## computing expected frequencies
p1 = (pgamma(3,shape=a.est,rate=l.est)-pgamma(0,shape=a.est,rate=l.est))*num_of_samples
p2 = (pgamma(6,shape=a.est,rate=l.est)-pgamma(3,shape=a.est,rate=l.est))*num_of_samples
p3 = (pgamma(9,shape=a.est,rate=l.est)-pgamma(6,shape=a.est,rate=l.est))*num_of_samples
p4 = (pgamma(12,shape=a.est,rate=l.est)-pgamma(9,shape=a.est,rate=l.est))*num_of_samples
p5 = (pgamma(Inf,shape=a.est,rate=l.est)-pgamma(12,shape=a.est,rate=l.est))*num_of_samples
f.ex<-c(p1, p2, p3, p4, p5) ## expected frequencies vector
f.os<-vector()
for(i in 1:5) f.os[i]<- table(x.gam.cut)[[i]] ## empirical frequencies
X2<-sum(((f.os-f.ex)^2)/f.ex) ## chi-square statistic
gdl<-5-2-1 ## degrees of freedom
1-pchisq(X2,gdl) ## p-value
dist <- combined[, "TD"]
x.gam.cut<-cut(dist,breaks=c(0,3,6,9,12,Inf)) ##binning data
table(x.gam.cut) ## binned data table
fit.gamma <- fitdist(dist, distr = "gamma", method = "mge", lower = c(0, 0))
# Check result
a.est = coefficients(fit.gamma)["shape"]
l.est = coefficients(fit.gamma)["rate"]
num_of_samples = length(dist)
#x.gam.cut
## computing expected frequencies
p1 = (pgamma(3,shape=a.est,rate=l.est)-pgamma(0,shape=a.est,rate=l.est))*num_of_samples
p2 = (pgamma(6,shape=a.est,rate=l.est)-pgamma(3,shape=a.est,rate=l.est))*num_of_samples
p3 = (pgamma(9,shape=a.est,rate=l.est)-pgamma(6,shape=a.est,rate=l.est))*num_of_samples
p4 = (pgamma(12,shape=a.est,rate=l.est)-pgamma(9,shape=a.est,rate=l.est))*num_of_samples
p5 = (pgamma(Inf,shape=a.est,rate=l.est)-pgamma(12,shape=a.est,rate=l.est))*num_of_samples
f.ex<-c(p1, p2, p3, p4, p5) ## expected frequencies vector
f.os<-vector()
for(i in 1:5) f.os[i]<- table(x.gam.cut)[[i]] ## empirical frequencies
X2<-sum(((f.os-f.ex)^2)/f.ex) ## chi-square statistic
gdl<-5-2-1 ## degrees of freedom
1-pchisq(X2,gdl) ## p-value
dist <- combined[, "TD"]
x.gam.cut<-cut(dist,breaks=c(0,3,6,9,12,Inf)) ##binning data
table(x.gam.cut) ## binned data table
fit.gamma <- fitdist(dist, distr = "gamma", method = "qge", lower = c(0, 0))
# Check result
a.est = coefficients(fit.gamma)["shape"]
l.est = coefficients(fit.gamma)["rate"]
num_of_samples = length(dist)
#x.gam.cut
## computing expected frequencies
p1 = (pgamma(3,shape=a.est,rate=l.est)-pgamma(0,shape=a.est,rate=l.est))*num_of_samples
p2 = (pgamma(6,shape=a.est,rate=l.est)-pgamma(3,shape=a.est,rate=l.est))*num_of_samples
p3 = (pgamma(9,shape=a.est,rate=l.est)-pgamma(6,shape=a.est,rate=l.est))*num_of_samples
p4 = (pgamma(12,shape=a.est,rate=l.est)-pgamma(9,shape=a.est,rate=l.est))*num_of_samples
p5 = (pgamma(Inf,shape=a.est,rate=l.est)-pgamma(12,shape=a.est,rate=l.est))*num_of_samples
f.ex<-c(p1, p2, p3, p4, p5) ## expected frequencies vector
f.os<-vector()
for(i in 1:5) f.os[i]<- table(x.gam.cut)[[i]] ## empirical frequencies
X2<-sum(((f.os-f.ex)^2)/f.ex) ## chi-square statistic
gdl<-5-2-1 ## degrees of freedom
1-pchisq(X2,gdl) ## p-value
dist <- combined[, "TD"]
x.gam.cut<-cut(dist,breaks=c(0,3,6,9,12,Inf)) ##binning data
table(x.gam.cut) ## binned data table
fit.gamma <- fitdist(dist, distr = "gamma", method = "qme", lower = c(0, 0))
# Check result
a.est = coefficients(fit.gamma)["shape"]
l.est = coefficients(fit.gamma)["rate"]
num_of_samples = length(dist)
#x.gam.cut
## computing expected frequencies
p1 = (pgamma(3,shape=a.est,rate=l.est)-pgamma(0,shape=a.est,rate=l.est))*num_of_samples
p2 = (pgamma(6,shape=a.est,rate=l.est)-pgamma(3,shape=a.est,rate=l.est))*num_of_samples
p3 = (pgamma(9,shape=a.est,rate=l.est)-pgamma(6,shape=a.est,rate=l.est))*num_of_samples
p4 = (pgamma(12,shape=a.est,rate=l.est)-pgamma(9,shape=a.est,rate=l.est))*num_of_samples
p5 = (pgamma(Inf,shape=a.est,rate=l.est)-pgamma(12,shape=a.est,rate=l.est))*num_of_samples
f.ex<-c(p1, p2, p3, p4, p5) ## expected frequencies vector
f.os<-vector()
for(i in 1:5) f.os[i]<- table(x.gam.cut)[[i]] ## empirical frequencies
X2<-sum(((f.os-f.ex)^2)/f.ex) ## chi-square statistic
gdl<-5-2-1 ## degrees of freedom
1-pchisq(X2,gdl) ## p-value
