peakDensity <- dnorm(mean, mean, sd)
g <- ggplot(marginalData, aes(x=marginalData[, col])) +
geom_histogram(aes(y = ..density..), binwidth = 1, colour="black", fill="white") +
stat_function(fun = dnorm, args = list(mean = mean(mean), sd = sd)) +
xlab(col) + ggtitle("Posterior Weight", paste(col, i, "bins")) +
annotate("text", x = mean, y = peakDensity * ((sd/3 *.1) + 1), label = paste("mean:", round(mean,2),",", "sd:", round(sd,2))) +
theme_bw()
print(g)
}
}
SWTIIIresults <- performSearch(6, effort, transactionFiles, c("TL", "TD", "DETs"))
# Plot classification results
for (i in 1:length(SWTIIIresults)) {
result <- SWTIIIresults[[i]]
df <- as.data.frame(t(subset(result$data, select = -c(Effort))))
g <- ggplot(data = df, aes(x = rownames(df), y = Aggregate)) +
geom_bar(stat = "identity") +
xlab("Category") +
ggtitle(paste("Classification Results:", i, "bins")) +
theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
cutsVec <- cutsAsVec(result$cuts)
g <- g + geom_text(data = data.frame(cutsVec), aes(label=cutsVec, col=cutsVec), alpha=0, x=1, y=1) +
theme(legend.key=element_blank(), legend.title = element_blank()) +
guides(colour=guide_legend(override.aes=list(size=0)), reverse = TRUE) +
theme_bw()
print(g)
}
# Plot predicted vs. actual effort values
predictedValuesSWTIII <- sapply(1:length(SWTIIIresults), function(i) {
predicted <- apply(SWTIIIresults[[i]]$data, 1, function(x) {
blmpredicted <- predict.blm(SWTIIIresults[[i]]$model, newdata = as.data.frame(t(x)))
#blmpredicted*SWTIIIresults[[i]]$normFactor
})
})
colnames(predictedValuesSWTIII) <- paste(1:length(SWTIIIresults), "Bins")
predictedValuesSWTIII <- subset(predictedValuesSWTIII, rownames(predictedValuesSWTIII) != "Aggregate")
predictedValuesSWTIII <- merge(as.data.frame(predictedValuesSWTIII), effort, by='row.names', all=TRUE)
rownames(predictedValuesSWTIII) <- predictedValuesSWTIII$Row.names
predictedValuesSWTIII$Row.names <- NULL
r2Vals <- apply(subset(predictedValuesSWTIII, select = -Effort), 2, function (x) {
dat <- data.frame(Predicted = x, Effort = predictedValuesSWTIII$Effort)
model <- lm(Effort ~ ., data = dat)
summary(model)$r.squared
})
r2Vals <- round(r2Vals, digits = 5)
r2Vals <- paste("r2:", r2Vals, sep = "")
predictedValues <- gather(predictedValuesSWTIII, numBins, Predicted, -Effort)
r2data_txt <- data.frame(label = as.character(r2Vals), numBins = paste(1:length(SWTIIIresults), "Bins"))
ggplot(predictedValues, aes(x = Predicted, y = Effort)) +
geom_point(shape = 1) + stat_smooth(method = "lm",  se = FALSE, fullrange = TRUE) +
facet_grid(. ~ numBins, scales = "free") + xlab("Predicted Effort") +
ylab("Actual Effort") + ggtitle("Goodness of Fit") +
theme(panel.spacing = unit(1, "lines")) +
geom_text(data = r2data_txt, size = 3, mapping = aes(x = -Inf, y = -Inf, label = label),
hjust = -0.1, vjust = -1) +
theme_bw()
# Plots cross validation results
MSEdata <- data.frame(NumBins = 1:length(SWTIIIresults), MSE = sapply(SWTIIIresults, function(x) { x$MSE }))
MMREdata <- data.frame(NumBins = 1:length(SWTIIIresults), MMRE = sapply(SWTIIIresults, function(x) { x$MMRE }))
PREDdata <- data.frame(NumBins = 1:length(SWTIIIresults), PRED = sapply(SWTIIIresults, function(x) { x$PRED }))
ggplot(data = MSEdata, aes(x = NumBins, y = log(MSE))) + geom_point(shape = 1) + geom_line() + ggtitle("MSE Results") +
theme_bw()
ggplot(data = MMREdata, aes(x = NumBins, y = MMRE)) + geom_point(shape = 1) + geom_line() + ggtitle("MMRE Results") +
theme_bw()
ggplot(data = PREDdata, aes(x = NumBins, y = PRED)) + geom_point(shape = 1) + geom_line() + ylab("PRED(0.25)") + ggtitle("PRED Results") +
theme_bw()
# Plot marginal posteriors for each parameter
for (i in 1:length(SWTIIIresults)) {
marginalData <- SWTIIIresults[[i]]$model[, !names(SWTIIIresults[[i]]$model) %in% c("(Intercept)", "sigma")]
if (is.vector(marginalData)) {
marginalData <- data.frame(TL1TD1DETs1 = marginalData)
}
for (col in names(marginalData)) {
mean <- mean(marginalData[, col])
sd <- sd(marginalData[, col])
peakDensity <- dnorm(mean, mean, sd)
g <- ggplot(marginalData, aes(x=marginalData[, col])) +
geom_histogram(aes(y = ..density..), binwidth = 1, colour="black", fill="white") +
stat_function(fun = dnorm, args = list(mean = mean(mean), sd = sd)) +
xlab(col) + ggtitle(paste("Posterior Weight", col, i, "bins")) +
annotate("text", x = mean, y = peakDensity * ((sd/3 *.1) + 1), label = paste("mean:", round(mean,2),",", "sd:", round(sd,2))) +
theme_bw()
print(g)
}
}
TNModelSelector <- 1;
TNModelPredictedValues <- as.data.frame(predictedValuesTN[, c(paste(TNModelSelector, "Bins", sep=" "))])
TNModelData <- TNresults[[TNModelSelector]][["data"]]
TNModelData <- TNModelData[rownames(TNModelData) != "Aggregate", ]
colnames(TNModelPredictedValues) <- c("TN")
rownames(TNModelPredictedValues) <- rownames(predictedValuesTN)
SWTIIModelSelector <- 5;
SWTIIModelPredictedValues = as.data.frame(predictedValuesSWTII[, c(paste(SWTIIModelSelector, "Bins", sep=" "))])
SWTIIModelData <- SWTIIresults[[SWTIIModelSelector]][["data"]]
SWTIIModelData <- SWTIIModelData[rownames(SWTIIModelData) != "Aggregate", ]
#print(SWTIIModelData)
colnames(SWTIIModelPredictedValues) <- c("SWTII")
rownames(SWTIIModelPredictedValues) <- rownames(predictedValuesSWTII)
SWTIIIModelSelector <- 5;
SWTIIIModelPredictedValues = as.data.frame(predictedValuesSWTIII[, c("5 Bins")])
SWTIIIModelData <- SWTIIIresults[[SWTIIIModelSelector]][["data"]]
SWTIIIModelData <- SWTIIIModelData[rownames(SWTIIIModelData) != "Aggregate", ]
colnames(SWTIIIModelPredictedValues) <- c("SWTIII")
rownames(SWTIIIModelPredictedValues) <- rownames(predictedValuesSWTIII)
predictedValues <- merge(TNModelPredictedValues, SWTIIModelPredictedValues, by='row.names', all=TRUE)
rownames(predictedValues) <- predictedValues$Row.names
predictedValues$Row.names <- NULL
predictedValues <- merge(predictedValues, SWTIIIModelPredictedValues, by='row.names', all=TRUE)
rownames(predictedValues) <- predictedValues$Row.names
predictedValues$Row.names <- NULL
predictedValues <- merge(predictedValues, effort, by='row.names', all=TRUE)
rownames(predictedValues) <- predictedValues$Row.names
predictedValues$Row.names <- NULL
r2Vals <- apply(subset(predictedValues, select = -Effort), 2, function (x) {
dat <- data.frame(Predicted = x, Effort = predictedValues$Effort)
model <- lm(Effort ~ ., data = dat)
summary(model)$r.squared
})
r2Vals <- round(r2Vals, digits = 5)
r2Vals <- paste("r2:", r2Vals, sep = "")
predictedValues <- gather(predictedValues, models, Predicted, -Effort)
r2data_txt <- data.frame(label = as.character(r2Vals), models = c("TN", "SWTII", "SWTIII"))
ggplot(predictedValues, aes(x = Predicted, y = Effort)) +
geom_point(shape = 1) + stat_smooth(method = "lm",  se = FALSE, fullrange = TRUE) +
facet_grid(. ~ models, scales = "free") + xlab("Predicted Effort") +
ylab("Actual Effort") + ggtitle("Goodness of Fit") +
theme(panel.spacing = unit(1, "lines")) +
geom_text(data = r2data_txt, size = 3, mapping = aes(x = -Inf, y = -Inf, label = label),
hjust = -0.1, vjust = -1)+
theme_bw()
#df <- read.csv("modelEvaluations-8-16-3.csv")
otherSizeMetricsData=modelData[c("Effort", "COCOMO_Estimate", "Priori_COCOMO_Estimate", "UCP")]
ret <- compareBetweenSizeMetrics(TNModelData, SWTIIModelData, SWTIIIModelData, otherSizeMetricsData)
cvResults <-ret[["cvResults"]]
print(cvResults)
avgPreds <- ret[["avgPreds"]]
print('average improvement by eucp')
print(colMeans(avgPreds[, "EUCP"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
print('average improvement by exucp')
print(colMeans(avgPreds[, "EXUCP"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
print('average improvement by ducp')
print(colMeans(avgPreds[, "DUCP"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
print('average improvement by ucp')
print(colMeans(avgPreds[, "UCP"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
print('average improvement by cocomo')
print(colMeans(avgPreds[, "COCOMO"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
print('average improvement by cocomo.apriori')
print(colMeans(avgPreds[, "COCOMO Apriori"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
#print(mean(avgPreds[, "EXUCP"] - avgPreds[,"UCP"]))
#print(mean(avgPreds[, "EXUCP"] - avgPreds[,"COCOMO"]))
#print(mean(avgPreds[, "EXUCP"] - avgPreds[,"COCOMO Apriori"]))
#print(mean(avgPreds[, "DUCP"] - avgPreds[,"EUCP"]))
#print(mean(avgPreds[, "DUCP"] - avgPreds[,"EXUCP"]))
avgPreds <- data.frame(avgPreds)
print(avgPreds)
meltAvgPreds = melt(avgPreds, id.vars="Pred")
colnames(meltAvgPreds) <- c("Pred", "Method", "Value")
print("melt avg preds info")
print(meltAvgPreds)
ggplot(meltAvgPreds) + theme_bw() + geom_point(aes(x=Pred, y=Value, group=Method,color=Method),size=3)+ xlab("Relative Deviation (%)") +
ylab("Percentage")+ theme(legend.position="bottom")
print("melt avg preds info as lines and smooth function")
ggplot(meltAvgPreds) + theme_bw() +
geom_line(aes(y=Value, x=Pred, group=Method,color=Method)) +
stat_smooth(aes(y=Value, x=Pred, group=Method,color=Method), method = lm, formula = y ~ poly(x, 10), se = FALSE)+ xlab("Relative Deviation (%)") +
ylab("Percentage")+ theme(legend.position="bottom")
print("melt avg preds info as dots and smooth function")
ggplot(meltAvgPreds) + theme_bw() +
geom_point(aes(x=Pred, y=Value, group=Method,color=Method,shape=Method),size=1.5) +
scale_shape_manual(values=c(0,1,2,3,4,5,6))+
stat_smooth(aes(x=Pred, y=Value, group=Method,color=Method), method = lm, formula = y ~ poly(x, 10), se = FALSE)+ xlab("Relative Deviation (%)") +
ylab("Percentage")+ theme(legend.position="bottom")
#source("transaction_weights_calibration3.R")
trainedModels = list()
trainedModels[["TNModel"]] = TNresults[[1]]
trainedModels[["SWTIIModel"]] = SWTIIresults[[4]]
trainedModels[["SWTIIIModel"]] = SWTIIIresults[[4]]
saveRDS(trainedModels, file="train_models.rds")
#extract parameters for NT
trainedModelParameters = list()
TNModelParameters = list()
TNModelParameters[["normFactor"]] = TNresults[[1]][["normFactor"]]
TNModelParameters[["cuts"]] = list()
for(i in rownames(TNresults[[1]][["cuts"]])){
TNModelParameters[["cuts"]][[i]] = TNresults[[1]][["cuts"]][i,]
}
levels <- names(TNresults[[1]][["model"]])
levels <- levels[levels != "sigma"]
TNModelParameters[["levels"]] = list()
for(i in levels){
TNModelParameters[["levels"]][[i]] = c(mean(TNresults[[1]][["model"]][[i]]), var(TNresults[[1]][["model"]][[i]]))
}
trainedModelParameters[["EUCP"]] = TNModelParameters
#extract parameters for SWTII
SWTIIModelParameters = list()
SWTIIModelParameters[["normFactor"]] = SWTIIresults[[4]][["normFactor"]]
SWTIIModelParameters[["cuts"]] = list()
for(i in rownames(SWTIIresults[[4]][["cuts"]])){
SWTIIModelParameters[["cuts"]][[i]] = SWTIIresults[[4]][["cuts"]][i,]
}
print(SWTIIModelParameters[["cuts"]])
levels <- names(SWTIIresults[[4]][["model"]])
levels <- levels[levels != "sigma"]
SWTIIModelParameters[["levels"]] = list()
for(i in levels){
SWTIIModelParameters[["levels"]][[i]] = c(mean(SWTIIresults[[4]][["model"]][[i]]), var(SWTIIresults[[4]][["model"]][[i]]))
}
trainedModelParameters[["EXUCP"]] = SWTIIModelParameters
#extract parameters for SWTIII
SWTIIIModelParameters = list()
SWTIIIModelParameters[["normFactor"]] = SWTIIIresults[[3]][["normFactor"]]
SWTIIIModelParameters[["cuts"]] = list()
for(i in rownames(SWTIIIresults[[3]][["cuts"]])){
SWTIIIModelParameters[["cuts"]][[i]] = SWTIIIresults[[3]][["cuts"]][i,]
}
levels <- names(SWTIIIresults[[3]][["model"]])
levels <- levels[levels != "sigma"]
SWTIIIModelParameters[["levels"]] = list()
for(i in levels){
SWTIIIModelParameters[["levels"]][[i]] = c(mean(SWTIIIresults[[3]][["model"]][[i]]), var(SWTIIIresults[[3]][["model"]][[i]]))
}
trainedModelParameters[["DUCP"]] = SWTIIIModelParameters
write(jsonlite::toJSON(trainedModelParameters,pretty = TRUE,auto_unbox = TRUE), "trained_model_parameters.json")
View(ret)
View(ret)
View(ret)
View(ret)
compareBetweenSizeMetrics <- function(TNModelData, SWTIIModelData, SWTIIIModelData, otherSizeMetricsData){
#useCaseData <- data[c("Effort", "EUCP", "EXUCP", "DUCP")]
# estimate the predication accuracy by n fold cross validation.
#Randomly shuffle the data
#useCaseData<-useCaseData[sample(nrow(useCaseData)),]
#Create 10 equally size folds
nfold = 5
folds <- cut(seq(1,nrow(TNModelData)),breaks=nfold,labels=FALSE)
#add cocomo and original use case points into the comparison
#otherSizeMetricsData=data[c("Effort", "COCOMO_Estimate", "Priori_COCOMO_Estimate", "UCP")];
#DataFrame=data.frame(Effort,UCP)
#Effort
#UCP
#OriginalUseCaseModel=lm(Effort~UCP,data=otherSizeMetricsData)
#summary(OriginalUseCaseModel)
#w=coef(OriginalUseCaseModel)["UCP"]
#otherSizeMetricsData$UCPEffort=w*otherSizeMetricsData$UCP
#otherSizeMetricsData<-otherSizeMetricsData[sample(nrow(otherSizeMetricsData)),]
#data structure to hold the data for 10 fold cross validation
foldResults <- matrix(nrow=nfold,ncol=24)
colnames(foldResults) <- c(
'eucp_mmre','eucp_pred15','eucp_pred25','eucp_pred50',
'exucp_mmre','exucp_pred15','exucp_pred25','exucp_pred50',
'ducp_mmre','ducp_pred15','ducp_pred25','ducp_pred50',
'ucp_mmre','ucp_pred15','ucp_pred25','ucp_pred50',
'cocomo_mmre','cocomo_pred15','cocomo_pred25','cocomo_pred50',
'cocomo_apriori_mmre','cocomo_apriori_pred15','cocomo_apriori_pred25','cocomo_apriori_pred50'
)
foldResults1 <- array(0,dim=c(50,6,nfold))
#Perform 10 fold cross validation
for(i in 1:nfold){
#Segement your data by fold using the which() function
#i = 1
testIndexes <- which(folds==i,arr.ind=TRUE)
testTNModelData <- TNModelData[testIndexes, ]
trainTNModelData <- TNModelData[-testIndexes, ]
testSWTIIModelData <- SWTIIModelData[testIndexes, ]
trainSWTIIModelData <- SWTIIModelData[-testIndexes, ]
testSWTIIIModelData <- SWTIIIModelData[testIndexes, ]
trainSWTIIIModelData <- SWTIIIModelData[-testIndexes, ]
otherTestData <- otherSizeMetricsData[testIndexes, ]
otherTrainData <- otherSizeMetricsData[-testIndexes,]
print('eucp testing set predication')
levels1 <- length(trainTNModelData)-1
normFactor1 <- calNormFactor(trainTNModelData, levels1)
print(normFactor1)
#normalizedData <- regressionData[rownames(regressionData) != "Aggregate", ]
#normalizedData$Effort <- normalizedData$Effort/normFactor
#bayesianModel <- bayesfit(lm(Effort ~ . - 1, normalizedData), 1000)
means1 <- genMeans(levels1)
#print(means)
covar1 <- genVariance(means1, 1)
bayesianModel1 <- bayesfit3(trainTNModelData, 100000, means1, covar1, normFactor1['mean'], normFactor1['var'])
#eucp.mre = apply(testData, 1, function(x))
eucp.predict = cbind(predicted=predict.blm(bayesianModel1, newdata = testTNModelData), actual=testTNModelData$Effort)
#print(eucp.predict)
eucp.mre = apply(eucp.predict, 1, function(x) abs(x[1] - x[2])/x[2])
eucp.mmre = mean(eucp.mre)
#print(eucp.mmre)
#eucp.preds = sapply(eucp.mre, function(x) calculatePreds(x))
eucp.pred15 = length(eucp.mre[eucp.mre<=0.15])/length(eucp.mre)
eucp.pred25 = length(eucp.mre[eucp.mre<=0.25])/length(eucp.mre)
eucp.pred50 = length(eucp.mre[eucp.mre<=0.50])/length(eucp.mre)
#print(c(eucp.pred15, eucp.pred25, eucp.pred50))
eucp.pred <- 0
for(j in 1:50){
eucp.pred <- c(eucp.pred, length(eucp.mre[eucp.mre<=0.01*j])/length(eucp.mre))
}
print('exucp testing set predication')
levels2 <- length(trainSWTIIModelData)-1
normFactor2 <- calNormFactor(trainSWTIIModelData, levels2)
#print(normFactor2)
#normalizedData <- regressionData[rownames(regressionData) != "Aggregate", ]
#normalizedData$Effort <- normalizedData$Effort/normFactor
#bayesianModel <- bayesfit(lm(Effort ~ . - 1, normalizedData), 1000)
means2 <- genMeans(levels2)
#print(means)
covar2 <- genVariance(means2, 1)
bayesianModel2 <- bayesfit3(trainSWTIIModelData, 100000, means2, covar2, normFactor2['mean'], normFactor2['var'])
exucp.predict = cbind(predicted=predict.blm(bayesianModel2, newdata = testSWTIIModelData), actual=testSWTIIModelData$Effort)
print(exucp.predict)
exucp.mre = apply(exucp.predict, 1, function(x) abs(x[1] - x[2])/x[2])
exucp.mmre = mean(exucp.mre)
print(exucp.mmre)
#exucp.preds = sapply(exucp.mre, function(x) calculatePreds(x))
exucp.pred15 = length(exucp.mre[exucp.mre<=0.15])/length(exucp.mre)
exucp.pred25 = length(exucp.mre[exucp.mre<=0.25])/length(exucp.mre)
exucp.pred50 = length(exucp.mre[exucp.mre<=0.50])/length(exucp.mre)
print(c(exucp.pred15, exucp.pred25, exucp.pred50))
exucp.pred <- 0
for(j in 1:50){
exucp.pred <- c(exucp.pred, length(exucp.mre[exucp.mre<=0.01*j])/length(exucp.mre))
}
print('ducp testing set predication')
levels3 <- length(trainSWTIIIModelData)-1
normFactor3 <- calNormFactor(trainSWTIIIModelData, levels3)
#print(normFactor3)
#print(levels3)
#normalizedData <- regressionData[rownames(regressionData) != "Aggregate", ]
#normalizedData$Effort <- normalizedData$Effort/normFactor
#bayesianModel <- bayesfit(lm(Effort ~ . - 1, normalizedData), 1000)
means3 <- genMeans(levels3)
#print(means)
covar3 <- genVariance(means3, 1)
bayesianModel3 <- bayesfit3(trainSWTIIIModelData, 100000, means3, covar3, normFactor3['mean'], normFactor3['var'])
#ducp.m = lm(Effort~DUCP, data=trainSWTIIIModelData)
ducp.predict = cbind(predicted=predict.blm(bayesianModel3, newdata = testSWTIIIModelData), actual=testSWTIIIModelData$Effort)
#print(ducp.predict)
ducp.mre = apply(ducp.predict, 1, function(x) abs(x[1] - x[2])/x[2])
ducp.mmre = mean(ducp.mre)
#print(ducp.mmre)
#ducp.preds = sapply(ducp.mre, function(x) calculatePreds(x))
ducp.pred15 = length(ducp.mre[ducp.mre<=0.15])/length(ducp.mre)
ducp.pred25 = length(ducp.mre[ducp.mre<=0.25])/length(ducp.mre)
ducp.pred50 = length(ducp.mre[ducp.mre<=0.50])/length(ducp.mre)
#print(c(ducp.pred15, ducp.pred25, ducp.pred50))
ducp.pred <- 0
for(j in 1:50){
ducp.pred <- c(ducp.pred, length(ducp.mre[ducp.mre<=0.01*j])/length(ducp.mre))
}
print('ucp testing set predication')
ucp.m = lm(Effort~UCP, data=otherTrainData)
ucp.predict = cbind(predicted=predict(ucp.m, otherTestData), actual=otherTestData$Effort)
print(ucp.predict)
ucp.mre = apply(ucp.predict, 1, function(x) abs(x[1] - x[2])/x[2])
ucp.mmre = mean(ucp.mre)
print(ucp.mmre)
#ucp.preds = sapply(ucp.mre, function(x) calculatePreds(x))
ucp.pred15 = length(ucp.mre[ucp.mre<=0.15])/length(ucp.mre)
ucp.pred25 = length(ucp.mre[ucp.mre<=0.25])/length(ucp.mre)
ucp.pred50 = length(ucp.mre[ucp.mre<=0.50])/length(ucp.mre)
print(c(ucp.pred15, ucp.pred25, ucp.pred50))
ucp.pred <- 0
for(j in 1:50){
ucp.pred <- c(ucp.pred, length(ucp.mre[ucp.mre<=0.01*j])/length(ucp.mre))
}
print('cocomo testing set predication')
COCOMO_EstimateTestData = otherTestData[!otherTestData$COCOMO_Estimate == 0, ]
cocomo.predict = cbind(predicted=COCOMO_EstimateTestData$COCOMO_Estimate, actual=COCOMO_EstimateTestData$Effort)
#print(cocomo.predict)
cocomo.mre = apply(cocomo.predict, 1, function(x) abs(x[1] - x[2])/x[2])
cocomo.mmre = mean(cocomo.mre)
#print(cocomo.mmre)
#cocomo.preds = sapply(cocomo.mre, function(x) calculatePreds(x))
cocomo.pred15 = length(cocomo.mre[cocomo.mre<=0.15])/length(cocomo.mre)
cocomo.pred25 = length(cocomo.mre[cocomo.mre<=0.25])/length(cocomo.mre)
cocomo.pred50 = length(cocomo.mre[cocomo.mre<=0.50])/length(cocomo.mre)
#print(c(cocomo.pred15, cocomo.pred25, cocomo.pred50))
cocomo.pred <- 0
for(j in 1:50){
cocomo.pred <- c(cocomo.pred, length(cocomo.mre[cocomo.mre<=0.01*j])/length(cocomo.mre))
}
#print("other test data");
#print(otherTestData);
print('cocomo apriori testing set predication')
cocomoAprioriEstimationTestData = otherTestData[!otherTestData$Priori_COCOMO_Estimate == 0,]
#print(cocomoAprioriEstimationTestData)
cocomo_apriori.predict = cbind(predicted=cocomoAprioriEstimationTestData$Priori_COCOMO_Estimate, actual=cocomoAprioriEstimationTestData$Effort)
#print(cocomo_apriori.predict)
cocomo_apriori.mre = apply(cocomo_apriori.predict, 1, function(x) abs(x[1] - x[2])/x[2])
cocomo_apriori.mmre = mean(cocomo_apriori.mre)
#print(cocomo_apriori.mmre)
#cocomo_apriori.preds = sapply(cocomo_apriori.mre, function(x) calculatePreds(x))
cocomo_apriori.pred15 = length(cocomo_apriori.mre[cocomo_apriori.mre<=0.15])/length(cocomo_apriori.mre)
cocomo_apriori.pred25 = length(cocomo_apriori.mre[cocomo_apriori.mre<=0.25])/length(cocomo_apriori.mre)
cocomo_apriori.pred50 = length(cocomo_apriori.mre[cocomo_apriori.mre<=0.50])/length(cocomo_apriori.mre)
#print(c(cocomo_apriori.pred15, cocomo_apriori.pred25, cocomo_apriori.pred50))
cocomo_apriori.pred <- 0
for(j in 1:50){
cocomo_apriori.pred <- c(cocomo_apriori.pred, length(cocomo_apriori.mre[cocomo_apriori.mre<=0.01*j])/length(cocomo_apriori.mre))
}
foldResults[i,] = c(
eucp.mmre,eucp.pred15,eucp.pred25,eucp.pred50,
exucp.mmre,exucp.pred15,exucp.pred25,exucp.pred50,
ducp.mmre,ducp.pred15,ducp.pred25,ducp.pred50,
ucp.mmre,ucp.pred15,ucp.pred25,ucp.pred50,
cocomo.mmre,cocomo.pred15,cocomo.pred25,cocomo.pred50,
cocomo_apriori.mmre,cocomo_apriori.pred15,cocomo_apriori.pred25,cocomo_apriori.pred50
)
foldResults1[,,i] = array(c(eucp.pred,exucp.pred,ducp.pred,ucp.pred,cocomo.pred,cocomo_apriori.pred),c(50,6))
}
#average out the folds.
cvResults <- c(
mean(foldResults[, 'eucp_mmre']),
mean(foldResults[, 'eucp_pred15']),
mean(foldResults[, 'eucp_pred25']),
mean(foldResults[, 'eucp_pred50']),
mean(foldResults[, 'exucp_mmre']),
mean(foldResults[, 'exucp_pred15']),
mean(foldResults[, 'exucp_pred25']),
mean(foldResults[, 'exucp_pred50']),
mean(foldResults[, 'ducp_mmre']),
mean(foldResults[, 'ducp_pred15']),
mean(foldResults[, 'ducp_pred25']),
mean(foldResults[, 'ducp_pred50']),
mean(foldResults[, 'ucp_mmre']),
mean(foldResults[, 'ucp_pred15']),
mean(foldResults[, 'ucp_pred25']),
mean(foldResults[, 'ucp_pred50']),
mean(foldResults[, 'cocomo_mmre']),
mean(foldResults[, 'cocomo_pred15']),
mean(foldResults[, 'cocomo_pred25']),
mean(foldResults[, 'cocomo_pred50']),
mean(foldResults[, 'cocomo_apriori_mmre']),
mean(foldResults[, 'cocomo_apriori_pred15']),
mean(foldResults[, 'cocomo_apriori_pred25']),
mean(foldResults[, 'cocomo_apriori_pred50'])
);
names(cvResults) <- c(
'eucp_mmre','eucp_pred15','eucp_pred25','eucp_pred50',
'exucp_mmre','exucp_pred15','exucp_pred25','exucp_pred50',
'ducp_mmre','ducp_pred15','ducp_pred25','ducp_pred50',
'ucp_mmre','ucp_pred15','ucp_pred25','ucp_pred50',
'cocomo_mmre','cocomo_pred15','cocomo_pred25','cocomo_pred50',
'cocomo_apriori_mmre','cocomo_apriori_pred15','cocomo_apriori_pred25','cocomo_apriori_pred50'
)
avgPreds <- matrix(nrow=50,ncol=7)
colnames(avgPreds) <- c("Pred","EUCP","EXUCP","DUCP", "UCP", "COCOMO", "COCOMO Apriori")
for(i in 1:50){
eucp_fold_mean = mean(foldResults1[i,1,]);
exucp_fold_mean = mean(foldResults1[i,2,]);
ducp_fold_mean = mean(foldResults1[i,3,]);
ucp_fold_mean = mean(foldResults1[i,4,]);
cocomo_fold_mean = mean(foldResults1[i,5,]);
cocomo_apriori_fold_mean = mean(foldResults1[i,6,]);
avgPreds[i,] <- c(i,eucp_fold_mean,exucp_fold_mean,ducp_fold_mean,ucp_fold_mean,cocomo_fold_mean,cocomo_apriori_fold_mean)
#print(i)
#print(avgPreds[i,])
}
ret <-list(cvResults = cvResults, avgPreds = avgPreds)
}
ret <- compareBetweenSizeMetrics(TNModelData, SWTIIModelData, SWTIIIModelData, otherSizeMetricsData)
n = 6
quantiles <- seq(1/n, 1 - (1/n), 1/n)
print(quantiles)
n = 6
quantiles <- seq(1/n, 1 - (1/n), 1/n)
print(quantiles)
n = 6
quantiles <- seq(1/n, 1 - (1/n), 1/n)
print(quantiles)
ret <- compareBetweenSizeMetrics(TNModelData, SWTIIModelData, SWTIIIModelData, otherSizeMetricsData)
#df <- read.csv("modelEvaluations-8-16-3.csv")
otherSizeMetricsData=modelData[c("Effort", "COCOMO_Estimate", "Priori_COCOMO_Estimate", "UCP")]
otherSizeMetricsData=modelData[c("Effort", "COCOMO_Estimate", "Priori_COCOMO_Estimate", "UCP")]
ret <- compareBetweenSizeMetrics(TNModelData, SWTIIModelData, SWTIIIModelData, otherSizeMetricsData)
cvResults <-ret[["cvResults"]]
print(cvResults)
avgPreds <- ret[["avgPreds"]]
print('average improvement by eucp')
print(colMeans(avgPreds[, "EUCP"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
print('average improvement by exucp')
print(colMeans(avgPreds[, "EXUCP"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
print('average improvement by ducp')
print(colMeans(avgPreds[, "DUCP"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
print('average improvement by ucp')
print(colMeans(avgPreds[, "UCP"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
print('average improvement by cocomo')
print(colMeans(avgPreds[, "COCOMO"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
print('average improvement by cocomo.apriori')
print(colMeans(avgPreds[, "COCOMO Apriori"] - avgPreds[,!colnames(avgPreds) %in% c("Pred")]))
#print(mean(avgPreds[, "EXUCP"] - avgPreds[,"UCP"]))
#print(mean(avgPreds[, "EXUCP"] - avgPreds[,"COCOMO"]))
#print(mean(avgPreds[, "EXUCP"] - avgPreds[,"COCOMO Apriori"]))
#print(mean(avgPreds[, "DUCP"] - avgPreds[,"EUCP"]))
#print(mean(avgPreds[, "DUCP"] - avgPreds[,"EXUCP"]))
avgPreds <- data.frame(avgPreds)
print(avgPreds)
meltAvgPreds = melt(avgPreds, id.vars="Pred")
colnames(meltAvgPreds) <- c("Pred", "Method", "Value")
print("melt avg preds info")
print(meltAvgPreds)
ggplot(meltAvgPreds) + theme_bw() + geom_point(aes(x=Pred, y=Value, group=Method,color=Method),size=3)+ xlab("Relative Deviation (%)") +
ylab("Percentage")+ theme(legend.position="bottom")
print("melt avg preds info as lines and smooth function")
ggplot(meltAvgPreds) + theme_bw() +
geom_line(aes(y=Value, x=Pred, group=Method,color=Method)) +
stat_smooth(aes(y=Value, x=Pred, group=Method,color=Method), method = lm, formula = y ~ poly(x, 10), se = FALSE)+ xlab("Relative Deviation (%)") +
ylab("Percentage")+ theme(legend.position="bottom")
print("melt avg preds info as dots and smooth function")
ggplot(meltAvgPreds) + theme_bw() +
geom_point(aes(x=Pred, y=Value, group=Method,color=Method,shape=Method),size=1.5) +
scale_shape_manual(values=c(0,1,2,3,4,5,6))+
stat_smooth(aes(x=Pred, y=Value, group=Method,color=Method), method = lm, formula = y ~ poly(x, 10), se = FALSE)+ xlab("Relative Deviation (%)") +
ylab("Percentage")+ theme(legend.position="bottom")
