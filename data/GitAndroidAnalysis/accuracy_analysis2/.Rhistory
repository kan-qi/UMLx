<<<<<<< HEAD
metric=dfHypothesis[,'metric'],
direction=dfHypothesis[,'direction'],
model1_mean=dfPValue[,'model1_mean'],
model2_mean=dfPValue[,'model2_mean'],
p_value=dfPValue[,'p_value'],
BH_p_value=dfPValue[,'BH_p_value'],
bonferroni_p_value=dfPValue[,'bonferroni_p_value'],
cohen_d=dfeffectS[,'cohen_d'])
return(sig_df)
}
sig_bs <- familywiseHypoTest(iterationResults=iterResults, accuracy_metrics[! accuracy_metrics %in% c("predRange")], model_names, "boot")
round_df <- function(df, digits) {
nums <- vapply(df, is.numeric, FUN.VALUE = logical(1))
df[,nums] <- round(df[,nums], digits = digits)
(df)
}
sig_bs_f = sig_bs[which(sig_bs$BH_p_value < 0.05),]
sig_bs_f = sig_bs_f[which(sig_bs_f$metric %in% c("mmre", "mdmre", "pred25")),]
sig_bs_f = sig_bs_f[which(sig_bs_f$model1 %in% c("tm3") | sig_bs_f$model2 %in% c("tm3")),]
sig_bs_f = sig_bs_f[order(sig_bs_f$bonferroni_p_value),]
sig_bs_f = round_df(sig_bs_f, 2)
print(sig_bs_f)
#identify the parirs that are not identified from the 84% overlaps.
nonOverlappingPairsIndices <- paste(nonOverlappingPairs$Model1, nonOverlappingPairs$Model2, nonOverlappingPairs$Metric, sep="-")
print(nonOverlappingPairsIndices)
sig_bs_f_indices <- paste(sig_bs_f$model1, sig_bs_f$model2, sig_bs_f$metric, sep="-")
print(sig_bs_f_indices)
sig_bs_f$index <- sig_bs_f_indices
`%ni%` <- Negate(`%in%`)
filtered_sig_bs_f = sig_bs_f[which(sig_bs_f$index %ni% nonOverlappingPairsIndices), ]
write.csv(filtered_sig_bs_f,'sig_bs_f.csv')
# Using the "sig_bs" results, create a graph to represent the direct graph for the models.
library(igraph)
for(metric_i in 1:length(accuracy_metrics)){
selectedData <- sig_bs[sig_bs$metric == metric_labels[metric_i],]
m <- matrix(0, nrow = length(models), ncol = length(models), byrow = FALSE)
colnames(m) <- names(models)
rownames(m) <- names(models)
for(i in 1:nrow(selectedData)){
if(selectedData$BH_p_value[i] < 0.05){
if(selectedData$direction[i] == "+"){
m[as.character(selectedData$model1[i]), as.character(selectedData$model2[i])] = round(selectedData$bonferroni_p_value[i], 3)
}else if(selectedData$direction[i] == "-"){
m[as.character(selectedData$model2[i]), as.character(selectedData$model1[i])] = round(selectedData$bonferroni_p_value[i], 3)
}
}
}
edge_val <- c()
# if A -> B -> C, remove edge A -> C
for(i in 1:length(models)){
for(j in 1:length(models)){
if(m[i,j] != 0){
edge_val <- c(edge_val, m[i,j])
for(k in 1:length(models)){
if(m[j,k] != 0)
m[i,k] = 0
}
}
}
}
#plot the directed graph
model_mean <- matrix(0, nrow = length(models), byrow = FALSE)
rownames(model_mean) <- names(models)
colnames(model_mean) <- "mean"
for(i in 1:nrow(selectedData)){
model_mean[which(rownames(model_mean) == selectedData[i,]$model1)] = round(selectedData[i,]$model1_mean, 3)
model_mean[which(rownames(model_mean) == selectedData[i,]$model2)] = round(selectedData[i,]$model2_mean, 3)
}
net=graph.adjacency(m,mode="directed",weighted=TRUE,diag=FALSE)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
title(main = metric_labels[metric_i])
}
View(sig_bs)
View(sig_bs)
View(sig_bs)
selectedData <- sig_bs[sig_bs$metric == metric_labels[metric_i],]
View(selectedData)
View(selectedData)
for(metric_i in 1:length(accuracy_metrics)){
if(accuracy_metrics[metric_i] == "predRange"){
next
}
selectedData <- sig_bs[sig_bs$metric == metric_labels[metric_i],]
m <- matrix(0, nrow = length(models), ncol = length(models), byrow = FALSE)
colnames(m) <- names(models)
rownames(m) <- names(models)
for(i in 1:nrow(selectedData)){
if(selectedData$BH_p_value[i] < 0.05){
if(selectedData$direction[i] == "+"){
m[as.character(selectedData$model1[i]), as.character(selectedData$model2[i])] = round(selectedData$bonferroni_p_value[i], 3)
}else if(selectedData$direction[i] == "-"){
m[as.character(selectedData$model2[i]), as.character(selectedData$model1[i])] = round(selectedData$bonferroni_p_value[i], 3)
}
}
}
edge_val <- c()
# if A -> B -> C, remove edge A -> C
for(i in 1:length(models)){
for(j in 1:length(models)){
if(m[i,j] != 0){
edge_val <- c(edge_val, m[i,j])
for(k in 1:length(models)){
if(m[j,k] != 0)
m[i,k] = 0
}
}
}
}
#plot the directed graph
model_mean <- matrix(0, nrow = length(models), byrow = FALSE)
rownames(model_mean) <- names(models)
colnames(model_mean) <- "mean"
for(i in 1:nrow(selectedData)){
model_mean[which(rownames(model_mean) == selectedData[i,]$model1)] = round(selectedData[i,]$model1_mean, 3)
model_mean[which(rownames(model_mean) == selectedData[i,]$model2)] = round(selectedData[i,]$model2_mean, 3)
}
net=graph.adjacency(m,mode="directed",weighted=TRUE,diag=FALSE)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
title(main = metric_labels[metric_i])
}
for(metric_i in 1:length(accuracy_metrics)){
print(accuracy_metrics[metric_i])
if(accuracy_metrics[metric_i] == "predRange"){
next
}
selectedData <- sig_bs[sig_bs$metric == metric_labels[metric_i],]
m <- matrix(0, nrow = length(models), ncol = length(models), byrow = FALSE)
colnames(m) <- names(models)
rownames(m) <- names(models)
for(i in 1:nrow(selectedData)){
if(selectedData$BH_p_value[i] < 0.05){
if(selectedData$direction[i] == "+"){
m[as.character(selectedData$model1[i]), as.character(selectedData$model2[i])] = round(selectedData$bonferroni_p_value[i], 3)
}else if(selectedData$direction[i] == "-"){
m[as.character(selectedData$model2[i]), as.character(selectedData$model1[i])] = round(selectedData$bonferroni_p_value[i], 3)
}
}
}
edge_val <- c()
# if A -> B -> C, remove edge A -> C
for(i in 1:length(models)){
for(j in 1:length(models)){
if(m[i,j] != 0){
edge_val <- c(edge_val, m[i,j])
for(k in 1:length(models)){
if(m[j,k] != 0)
m[i,k] = 0
}
}
}
}
#plot the directed graph
model_mean <- matrix(0, nrow = length(models), byrow = FALSE)
rownames(model_mean) <- names(models)
colnames(model_mean) <- "mean"
for(i in 1:nrow(selectedData)){
model_mean[which(rownames(model_mean) == selectedData[i,]$model1)] = round(selectedData[i,]$model1_mean, 3)
model_mean[which(rownames(model_mean) == selectedData[i,]$model2)] = round(selectedData[i,]$model2_mean, 3)
}
net=graph.adjacency(m,mode="directed",weighted=TRUE,diag=FALSE)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
title(main = metric_labels[metric_i])
}
=======
sapply(data, function(x) sum(is.na(x)))
## Impute
library(mice)
library(randomForest)
# perform mice imputation, based on random forests.
# print(md.pattern(data))
miceMod <- mice(data, method="rf", print=FALSE, remove_collinear = TRUE)
# generate the completed data.
data.imputed <- complete(miceMod)
# remove collinear columns
coli <- findLinearCombos(data.imputed)
data.done <- data.imputed[, -coli$remove]
data.done$Effort <- dataset$Effort
return(data.done)
}
#define the lasso model
m_fit.lasso <- function(lasso,dataset){
#dataset = modelData
#lasso = list()
#ind_variables = c("Activity_Num", "Component_Num", "Precedence_Num",	"Stimulus_Num",	"Response_Num",	"Tran_Num",	"Boundary_Num")
cleanData <- clean(dataset)
#keep the columns that have been changed and set into the ind_variables
#ind_variables <- setdiff(names(dataset), names(cleanData))
#colNames <- names(cleanData)
#for(i in 1:length(colNames)){
#  if(!identical(dataset[, colNames[i]], cleanData[, colNames[i]])){
#    ind_variables <- c(ind_variables, colNames[i])
#  }
#}
ind_variables <- colnames(cleanData[, colnames(cleanData)!="Effort"])
x_data <- data.matrix(cleanData[, ind_variables])
y_data <- data.matrix(cleanData[, c("Effort")])
#lasso_lm <- glmnet(x = x_data, y = y_data, alpha = 1, standardize = T)
set.seed(2)
lambda_list <- Lasso_range(x_data,y_data,100)
cvfit = cv.glmnet(x_data,y_data,
standardize = T, lambda = lambda_list, type.measure = 'mse', nfolds = 5, alpha = 1)
lasso_lm = cvfit$glmnet.fit
#print(lasso_lm$lambda)
#plot(lasso_lm)
#for 10 biggest final features
#plot_glmnet(lasso_lm)                             # default colors
#plot_glmnet(lasso_lm, label=10)
lasso$m = lasso_lm
lasso$m$cv_lambda = min(cvfit$cvm)
lasso$m$cvfit = cvfit
lasso$m$ind_variables = ind_variables
lasso$m$lambda_list = lambda_list
lasso
}
m_predict.lasso <- function(lasso, testData){
#testData = modelData[2, ]
#testData[,lasso$m$ind_variables]
predicted <- predict(lasso$m,newx=data.matrix(testData[,lasso$m$ind_variables]),s=lasso$m$cv_lambda)
predicted_names <- rownames(predicted)
predicted <- as.vector(predicted[,1])
names(predicted) <- predicted_names
predicted
}
lasso_model <- function(dataset){
parameters = list()
}
benchmarkResults <- modelBenchmark(models, modelData)
library(glmnet)
library(plotmo) # for plot_glmnet
library(mice)
library(randomForest)
library(caret)
Lasso_range = function(x, y, k){
# inputs:
# x_matrix, a matrix containing independent variables
# y: vector of dependent varaibles
# k: the length of sequence
# output:
# seq: a sequence of lambdaa from high to low
x = x_data
y = y_data
k = 100
# define my own scale function to simulate that in glmnet
myscale = function(x) sqrt(sum((x - mean(x)) ^ 2) / length(x))
# normalize x
sx = as.matrix(scale(x, scale = apply(x, 2, myscale)))
# sy = as.vector(scale(y, scale = myscale(y)))
max_lambda = max(abs(colSums(sx * as.vector(y)))) / dim(sx)[1]
# The default depends on the sample size nobs relative to the number of variables nvars.
# If nobs > nvars, the default is 0.0001, close to zero.
# If nobs < nvars, the default is 0.01.
# A very small value of lambda.min.ratio will lead to a saturated fit in the nobs < nvars case.
ratio = 0
if(dim(sx)[1] > dim(sx)[2]){
ratio = 0.0001
}else{
ratio = 0.01
}
min_lambda = max_lambda * ratio
log_seq = seq(from  = log(min_lambda), to = log(max_lambda), length.out = k)
seq = sort(exp(log_seq), decreasing = T)
#print(seq)
return(seq)
}
#Lasso_range(x_data,y_data, 100)
cv_lasso_model = function(x_data,y_data){
set.seed(2)
lambda_list <- Lasso_range(x_data,y_data,100)
percent = 50
cvfit = cv.glmnet(x_data,y_data,
standardize = T, type.measure = 'mse', nfolds = 5, alpha = 1)
#print(cvfit$lambda)
# # 5 fold cross validation
k <- 5
#
# function to calculate MMRE
calcMMRE <- function(testData,pred){
mmre <- abs(testData - pred)/testData
mean_value <- mean(mmre)
mean_value
}
# # function to calculate PRED
calcPRED <- function(testData,pred,percent){
value <- abs(testData - pred)/testData
percent_value <- percent/100
pred_value <- value <= percent_value
mean(pred_value)
}
#
folds <- cut(seq(1,nrow(x_data)),breaks=k,labels=FALSE)
mean_mmre <- vector("list",k)
mean_pred <- vector("list",k)
overall_mean_mmre <- vector("list",100)
overall_mean_pred <- vector("list",100)
for(iterator in seq(1,100)){
for(i in 1:k){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData <- y_data[testIndexes]
pred <- predict(cvfit,newx=x_data,s=lambda_list[[iterator]])
mean_mmre[[i]] <- calcMMRE(testData,pred[testIndexes])
mean_pred[[i]] <- calcPRED(testData,pred[testIndexes],percent)
}
overall_mean_mmre[[iterator]] <- mean(as.numeric(mean_mmre))
overall_mean_pred[[iterator]] <- mean(as.numeric(mean_pred))
}
plot(log(lambda_list),overall_mean_mmre,xlab="log(Lambda)",ylab="MMRE")
lines(log(lambda_list),overall_mean_mmre,xlim=range(log(lambda_list)), ylim=range(overall_mean_mmre), pch=16)
plot(log(lambda_list),overall_mean_pred,xlab="log(Lambda)",ylab = "PRED")
lines(log(lambda_list),overall_mean_pred,xlim=range(log(lambda_list)), ylim=range(overall_mean_pred), pch=16)
}
# Preprocess dataset
clean <- function(dataset){
# numeric data only
numeric_columns <- unlist(lapply(dataset, is.numeric))
data.numeric <- dataset[, numeric_columns]
data.numeric <- data.frame(apply(dataset, 2, as.numeric))
# remove near zero variance columns
nzv_cols <- nearZeroVar(data.numeric)
if(length(nzv_cols) > 0) {
data <- data.numeric[, -nzv_cols]
}
sapply(data, function(x) sum(is.na(x)))
## Impute
# perform mice imputation, based on random forests.
# print(md.pattern(data))
miceMod <- mice(data, method="rf", print=FALSE, remove_collinear = TRUE)
# generate the completed data.
data.imputed <- complete(miceMod)
# remove collinear columns
coli <- findLinearCombos(data.imputed)
data.done <- data.imputed[, -coli$remove]
data.done$Effort <- dataset$Effort
return(data.done)
}
#define the lasso model
m_fit.lasso <- function(lasso,dataset){
#dataset = modelData
#lasso = list()
#ind_variables = c("Activity_Num", "Component_Num", "Precedence_Num",	"Stimulus_Num",	"Response_Num",	"Tran_Num",	"Boundary_Num")
cleanData <- clean(dataset)
#keep the columns that have been changed and set into the ind_variables
#ind_variables <- setdiff(names(dataset), names(cleanData))
#colNames <- names(cleanData)
#for(i in 1:length(colNames)){
#  if(!identical(dataset[, colNames[i]], cleanData[, colNames[i]])){
#    ind_variables <- c(ind_variables, colNames[i])
#  }
#}
ind_variables <- colnames(cleanData[, colnames(cleanData)!="Effort"])
x_data <- data.matrix(cleanData[, ind_variables])
y_data <- data.matrix(cleanData[, c("Effort")])
#lasso_lm <- glmnet(x = x_data, y = y_data, alpha = 1, standardize = T)
set.seed(2)
lambda_list <- Lasso_range(x_data,y_data,100)
cvfit = cv.glmnet(x_data,y_data,
standardize = T, lambda = lambda_list, type.measure = 'mse', nfolds = 5, alpha = 1)
lasso_lm = cvfit$glmnet.fit
#print(lasso_lm$lambda)
#plot(lasso_lm)
#for 10 biggest final features
#plot_glmnet(lasso_lm)                             # default colors
#plot_glmnet(lasso_lm, label=10)
lasso$m = lasso_lm
lasso$m$cv_lambda = min(cvfit$cvm)
lasso$m$cvfit = cvfit
lasso$m$ind_variables = ind_variables
lasso$m$lambda_list = lambda_list
lasso
}
m_predict.lasso <- function(lasso, testData){
#testData = modelData[2, ]
#testData[,lasso$m$ind_variables]
predicted <- predict(lasso$m,newx=data.matrix(testData[,lasso$m$ind_variables]),s=lasso$m$cv_lambda)
predicted_names <- rownames(predicted)
predicted <- as.vector(predicted[,1])
names(predicted) <- predicted_names
predicted
}
lasso_model <- function(dataset){
parameters = list()
}
benchmarkResults <- modelBenchmark(models, modelData)
library(glmnet)
library(plotmo) # for plot_glmnet
library(mice)
library(randomForest)
library(caret)
Lasso_range = function(x, y, k){
# inputs:
# x_matrix, a matrix containing independent variables
# y: vector of dependent varaibles
# k: the length of sequence
# output:
# seq: a sequence of lambdaa from high to low
x = x_data
y = y_data
k = 100
# define my own scale function to simulate that in glmnet
myscale = function(x) sqrt(sum((x - mean(x)) ^ 2) / length(x))
# normalize x
sx = as.matrix(scale(x, scale = apply(x, 2, myscale)))
# sy = as.vector(scale(y, scale = myscale(y)))
max_lambda = max(abs(colSums(sx * as.vector(y)))) / dim(sx)[1]
# The default depends on the sample size nobs relative to the number of variables nvars.
# If nobs > nvars, the default is 0.0001, close to zero.
# If nobs < nvars, the default is 0.01.
# A very small value of lambda.min.ratio will lead to a saturated fit in the nobs < nvars case.
ratio = 0
if(dim(sx)[1] > dim(sx)[2]){
ratio = 0.0001
}else{
ratio = 0.01
}
min_lambda = max_lambda * ratio
log_seq = seq(from  = log(min_lambda), to = log(max_lambda), length.out = k)
seq = sort(exp(log_seq), decreasing = T)
#print(seq)
return(seq)
}
#Lasso_range(x_data,y_data, 100)
cv_lasso_model = function(x_data,y_data){
set.seed(2)
lambda_list <- Lasso_range(x_data,y_data,100)
percent = 50
cvfit = cv.glmnet(x_data,y_data,
standardize = T, type.measure = 'mse', nfolds = 5, alpha = 1)
#print(cvfit$lambda)
# # 5 fold cross validation
k <- 5
#
# function to calculate MMRE
calcMMRE <- function(testData,pred){
mmre <- abs(testData - pred)/testData
mean_value <- mean(mmre)
mean_value
}
# # function to calculate PRED
calcPRED <- function(testData,pred,percent){
value <- abs(testData - pred)/testData
percent_value <- percent/100
pred_value <- value <= percent_value
mean(pred_value)
}
#
folds <- cut(seq(1,nrow(x_data)),breaks=k,labels=FALSE)
mean_mmre <- vector("list",k)
mean_pred <- vector("list",k)
overall_mean_mmre <- vector("list",100)
overall_mean_pred <- vector("list",100)
for(iterator in seq(1,100)){
for(i in 1:k){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData <- y_data[testIndexes]
pred <- predict(cvfit,newx=x_data,s=lambda_list[[iterator]])
mean_mmre[[i]] <- calcMMRE(testData,pred[testIndexes])
mean_pred[[i]] <- calcPRED(testData,pred[testIndexes],percent)
}
overall_mean_mmre[[iterator]] <- mean(as.numeric(mean_mmre))
overall_mean_pred[[iterator]] <- mean(as.numeric(mean_pred))
}
plot(log(lambda_list),overall_mean_mmre,xlab="log(Lambda)",ylab="MMRE")
lines(log(lambda_list),overall_mean_mmre,xlim=range(log(lambda_list)), ylim=range(overall_mean_mmre), pch=16)
plot(log(lambda_list),overall_mean_pred,xlab="log(Lambda)",ylab = "PRED")
lines(log(lambda_list),overall_mean_pred,xlim=range(log(lambda_list)), ylim=range(overall_mean_pred), pch=16)
}
# Preprocess dataset
clean <- function(dataset){
# numeric data only
numeric_columns <- unlist(lapply(dataset, is.numeric))
data.numeric <- dataset[, numeric_columns]
data.numeric <- data.frame(apply(dataset, 2, as.numeric))
# remove near zero variance columns
nzv_cols <- nearZeroVar(data.numeric)
if(length(nzv_cols) > 0) {
data <- data.numeric[, -nzv_cols]
}
sapply(data, function(x) sum(is.na(x)))
## Impute
# perform mice imputation, based on random forests.
# print(md.pattern(data))
miceMod <- mice(data, method="rf", print=FALSE, remove_collinear = TRUE)
# generate the completed data.
data.imputed <- mice::complete(miceMod)
# remove collinear columns
coli <- findLinearCombos(data.imputed)
data.done <- data.imputed[, -coli$remove]
data.done$Effort <- dataset$Effort
return(data.done)
}
#define the lasso model
m_fit.lasso <- function(lasso,dataset){
#dataset = modelData
#lasso = list()
#ind_variables = c("Activity_Num", "Component_Num", "Precedence_Num",	"Stimulus_Num",	"Response_Num",	"Tran_Num",	"Boundary_Num")
cleanData <- clean(dataset)
#keep the columns that have been changed and set into the ind_variables
#ind_variables <- setdiff(names(dataset), names(cleanData))
#colNames <- names(cleanData)
#for(i in 1:length(colNames)){
#  if(!identical(dataset[, colNames[i]], cleanData[, colNames[i]])){
#    ind_variables <- c(ind_variables, colNames[i])
#  }
#}
ind_variables <- colnames(cleanData[, colnames(cleanData)!="Effort"])
x_data <- data.matrix(cleanData[, ind_variables])
y_data <- data.matrix(cleanData[, c("Effort")])
#lasso_lm <- glmnet(x = x_data, y = y_data, alpha = 1, standardize = T)
set.seed(2)
lambda_list <- Lasso_range(x_data,y_data,100)
cvfit = cv.glmnet(x_data,y_data,
standardize = T, lambda = lambda_list, type.measure = 'mse', nfolds = 5, alpha = 1)
lasso_lm = cvfit$glmnet.fit
#print(lasso_lm$lambda)
#plot(lasso_lm)
#for 10 biggest final features
#plot_glmnet(lasso_lm)                             # default colors
#plot_glmnet(lasso_lm, label=10)
lasso$m = lasso_lm
lasso$m$cv_lambda = min(cvfit$cvm)
lasso$m$cvfit = cvfit
lasso$m$ind_variables = ind_variables
lasso$m$lambda_list = lambda_list
lasso
}
m_predict.lasso <- function(lasso, testData){
#testData = modelData[2, ]
#testData[,lasso$m$ind_variables]
predicted <- predict(lasso$m,newx=data.matrix(testData[,lasso$m$ind_variables]),s=lasso$m$cv_lambda)
predicted_names <- rownames(predicted)
predicted <- as.vector(predicted[,1])
names(predicted) <- predicted_names
predicted
}
lasso_model <- function(dataset){
parameters = list()
}
benchmarkResults <- modelBenchmark(models, modelData)
fitResults <- benchmarkResults$fitResults
goodness_fit_metrics = benchmarkResults$goodness_fit_metrics
goodnessRankResults = data.frame(matrix(ncol=length(goodness_fit_metrics), nrow=length(fitResults)))
colnames(goodnessRankResults) <- goodness_fit_metrics
goodnessRankResults$model_labels = names(fitResults)
for (i in 1:length(goodness_fit_metrics)){
g = goodness_fit_metrics[i]
selectData = data.frame(matrix(ncol=0, nrow=length(fitResults)))
selectData$model_labels <- names(fitResults)
selectData[, g] <- c()
for(j in 1:length(fitResults)){
m = fitResults[[j]]
m_name = names(fitResults)[j]
selectData[m_name, g] <- m[[g]]
}
selectData[paste("rank", i, sep = "")] <- rank(selectData[,g], ties.method = "min")
goodnessRankResults <- merge(goodnessRankResults, selectData, by = "model_labels", all=FALSE)
}
write.csv(goodnessRankResults, "goodness_rank_results.csv")
>>>>>>> 0ee63dc8d7f46ced13faa9d30cddee827ccacaed
model_names <- benchmarkResults$model_names
accuracy_metrics <- benchmarkResults$accuracy_metrics
#plot for the cross validation results
cvResults <- benchmarkResults$cvResults
avgPreds <- cvResults[["avgPreds"]]
avgPreds <- data.frame(avgPreds)
meltAvgPreds = melt(avgPreds, id.vars="Pred")
colnames(meltAvgPreds) <- c("Pred", "Method", "Value")
model_labels <- c()
for(i in 1:length(models)){
for(j in 1:length(accuracy_metrics)){
model_labels = c(model_labels, names(models)[i])
}
}
metric_labels <- c()
for(i in 1:length(models)){
for(j in 1:length(accuracy_metrics)){
metric_labels = c(metric_labels, accuracy_metrics[j])
}
}
<<<<<<< HEAD
=======
print("melt avg preds info")
ggplot(meltAvgPreds) + theme_bw() + geom_point(aes(x=Pred, y=Value, group=Method,color=Method),size=3)+ xlab("Relative Deviation (%)") +
ylab("Percentage of Estimates <= x%")+ theme(legend.position="bottom")
print("melt avg preds info as lines and smooth function")
ggplot(meltAvgPreds) + theme_bw() +
geom_line(aes(y=Value, x=Pred, group=Method,color=Method)) +
stat_smooth(aes(y=Value, x=Pred, group=Method,color=Method), method = lm, formula = y ~ poly(x, 10), se = FALSE)+ xlab("Relative Deviation (%)") +
ylab("Percentage of Estimates <= x%")+ theme(legend.position="bottom")
>>>>>>> 0ee63dc8d7f46ced13faa9d30cddee827ccacaed
print("melt avg preds info as dots and smooth function")
ggplot(meltAvgPreds) + theme_bw() +
geom_point(aes(x=Pred, y=Value, group=Method,color=Method,shape=Method),size=1.5) +
scale_shape_manual(values=c(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15))+
stat_smooth(aes(x=Pred, y=Value, group=Method,color=Method), method = lm, formula = y ~ poly(x, 10), se = FALSE)+ xlab("Relative Deviation (%)") +
ylab("Percentage of Estimates <= x%")+ theme(legend.position="bottom")
#rank the cv results of different metric
cvAccuracyResults <- data.frame(cvResults$accuracyResults)
cvAccuracyResults$model_labels <- model_labels
print(model_labels)
cvAccuracyResults$metric_labels <- accuracy_metrics
#calculate ranking results
cvRankResults <- data.frame(names(models))
names(cvRankResults)<-c("model_labels")
for (i in 1:length(accuracy_metrics)){
g = accuracy_metrics[i]
selectedData <- cvAccuracyResults[cvAccuracyResults$metric_labels == g,]
selectedData <- selectedData[,-3]#delete the metric_labels
colnames(selectedData)<-c(g, "model_labels")
if(g == "mmre" || g == "mdmre" || g == "mae"){
selectedData[paste("rank", i, sep = "")] <- rank(selectedData[,1], ties.method = "min")
}else{
selectedData[paste("rank", i, sep = "")] <- rank(-selectedData[,1], ties.method = "min")
}
cvRankResults <- merge(cvRankResults, selectedData, by = "model_labels", all=FALSE)
}
#make a total rank(rank*) base on the ranki
rank_sum <- vector(mode = "integer",length = length(models))
for (i in 1:length(models)){
selectedData <- cvRankResults[i,]
for(j in 1:length(accuracy_metrics)){
rank_sum[i] <- rank_sum[i] + selectedData[,2*j+1]
}
}
rank_sum <- rank(rank_sum, ties.method = "min")
print(rank_sum)
cvRankResults["rank*"] <- rank_sum
cvRankResults <- cvRankResults[order(cvRankResults$'rank*'),]
#change the first line as the row name
rownames(cvRankResults) = cvRankResults[,1]
cvRankResults <- cvRankResults[,-1]
print(round(cvRankResults,2))
write.csv(round(cvRankResults,2), "model_ranking_results.csv")
# draw histogram base on ranking
library(ggplot2)
modelsName = rownames(cvRankResults)
p <- list()
for(i in 1:length(accuracy_metrics)){
g = paste("rank", i, sep = "")
selectedData <- cvRankResults[names(cvRankResults) == g]
names(selectedData) <- c("rank");
p[[i]] <- ggplot(selectedData, aes(x=modelsName, y=rank, fill=modelsName)) +
geom_bar(stat="identity", colour = "black") +
#scale_y_discrete(expand = c(0, 0)) +
guides(fill = guide_legend(title = "MODEL", nrow = 1)) +
geom_text(aes(label = rank, vjust = -0.3, hjust = 0.5)) +
#ggtitle(accuracy_metrics[i]) +
labs(caption=toupper(accuracy_metrics[i])) +
theme(plot.caption = element_text(hjust=0.5, size=rel(1)),
#axis.line=element_blank(),
axis.title=element_blank(), axis.text=element_blank(),axis.ticks=element_blank(), panel.background = element_blank())
}
library("cowplot")
prow <- plot_grid( p[[1]] + theme(legend.position="none"),
p[[2]] + theme(legend.position="none"),
p[[3]] + theme(legend.position="none"),
p[[4]] + theme(legend.position="none"),
p[[5]] + theme(legend.position="none"),
p[[6]] + theme(legend.position="none"),
align = 'vh',
hjust = -1,
nrow = 1
)
legend_b <- get_legend(p[[1]] + theme(legend.position="bottom", legend.justification="center"))
title <- ggdraw() + draw_label("Ranking Result for Cross Validation", fontface='bold')
p_cvRank <- plot_grid(title, prow, legend_b, ncol = 1, rel_heights = c(.2 , 1, .1))
p_cvRank
# draw overall ranking histogram
selectedData <- cvRankResults[names(cvRankResults) == "rank*"]
names(selectedData) <- c("rank");
p_cvAllRank <- ggplot(selectedData, aes(x=modelsName, y=rank, fill=modelsName)) +
geom_bar(stat="identity", colour = "black", width = 0.7) +
#scale_y_discrete(expand = c(0, 0)) +
guides(fill = guide_legend(title = "MODEL", nrow = 1)) +
geom_text(aes(label = rank, vjust = -0.4, hjust = 0.5)) +
ggtitle("Overall Ranking Result for Cross Validation") +
#labs(caption=toupper("Total Rank")) +
theme(plot.caption = element_text(hjust=0.5, size=rel(1)), legend.position = "bottom",
plot.title = element_text(hjust = 0.5),
#axis.line=element_blank(),
axis.title=element_blank(), axis.text=element_blank(),axis.ticks=element_blank(),  panel.background = element_blank())
p_cvAllRank
<<<<<<< HEAD
sig_bs <- familywiseHypoTest(iterationResults=iterResults, accuracy_metrics[! accuracy_metrics %in% c("predRange")], model_names, "boot")
round_df <- function(df, digits) {
nums <- vapply(df, is.numeric, FUN.VALUE = logical(1))
df[,nums] <- round(df[,nums], digits = digits)
(df)
}
sig_bs_f = sig_bs[which(sig_bs$BH_p_value < 0.05),]
sig_bs_f = sig_bs_f[which(sig_bs_f$metric %in% c("mmre", "mdmre", "pred25")),]
sig_bs_f = sig_bs_f[which(sig_bs_f$model1 %in% c("tm3") | sig_bs_f$model2 %in% c("tm3")),]
sig_bs_f = sig_bs_f[order(sig_bs_f$bonferroni_p_value),]
sig_bs_f = round_df(sig_bs_f, 2)
print(sig_bs_f)
#identify the parirs that are not identified from the 84% overlaps.
nonOverlappingPairsIndices <- paste(nonOverlappingPairs$Model1, nonOverlappingPairs$Model2, nonOverlappingPairs$Metric, sep="-")
print(nonOverlappingPairsIndices)
sig_bs_f_indices <- paste(sig_bs_f$model1, sig_bs_f$model2, sig_bs_f$metric, sep="-")
print(sig_bs_f_indices)
sig_bs_f$index <- sig_bs_f_indices
`%ni%` <- Negate(`%in%`)
filtered_sig_bs_f = sig_bs_f[which(sig_bs_f$index %ni% nonOverlappingPairsIndices), ]
write.csv(filtered_sig_bs_f,'sig_bs_f.csv')
# Using the "sig_bs" results, create a graph to represent the direct graph for the models.
library(igraph)
for(metric_i in 1:length(accuracy_metrics)){
print(accuracy_metrics[metric_i])
if(accuracy_metrics[metric_i] == "predRange"){
next
}
selectedData <- sig_bs[sig_bs$metric == metric_labels[metric_i],]
m <- matrix(0, nrow = length(models), ncol = length(models), byrow = FALSE)
colnames(m) <- names(models)
rownames(m) <- names(models)
for(i in 1:nrow(selectedData)){
if(selectedData$BH_p_value[i] < 0.05){
if(selectedData$direction[i] == "+"){
m[as.character(selectedData$model1[i]), as.character(selectedData$model2[i])] = round(selectedData$bonferroni_p_value[i], 3)
}else if(selectedData$direction[i] == "-"){
m[as.character(selectedData$model2[i]), as.character(selectedData$model1[i])] = round(selectedData$bonferroni_p_value[i], 3)
}
}
}
edge_val <- c()
# if A -> B -> C, remove edge A -> C
for(i in 1:length(models)){
for(j in 1:length(models)){
if(m[i,j] != 0){
edge_val <- c(edge_val, m[i,j])
for(k in 1:length(models)){
if(m[j,k] != 0)
m[i,k] = 0
}
}
}
}
#plot the directed graph
model_mean <- matrix(0, nrow = length(models), byrow = FALSE)
rownames(model_mean) <- names(models)
colnames(model_mean) <- "mean"
for(i in 1:nrow(selectedData)){
model_mean[which(rownames(model_mean) == selectedData[i,]$model1)] = round(selectedData[i,]$model1_mean, 3)
model_mean[which(rownames(model_mean) == selectedData[i,]$model2)] = round(selectedData[i,]$model2_mean, 3)
}
net=graph.adjacency(m,mode="directed",weighted=TRUE,diag=FALSE)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
title(main = metric_labels[metric_i])
}
tkplot(net)
tkplot(net)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*2.0,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*10.0,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*12.0,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*30.0,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*100.0,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
graph = plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*100.0,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout_with_fr(net)*100.0,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
title(main = metric_labels[metric_i])
net=graph.adjacency(m,mode="directed",weighted=TRUE,diag=FALSE)
tkplot(net)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.random,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
title(main = metric_labels[metric_i])
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*100.0,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
title(main = metric_labels[metric_i])
}
tkplot(net, canvas.width=450, canvas.height=450)
g <- make_ring(10)
tkplot(g)
knitr::opts_chunk$set(echo = TRUE)
g <- make_ring(10)
tkplot(g)
g <- make_star(10, center=10)
E(g)$width <- sample(1:10, ecount(g), replace=TRUE)
lay <- layout_nicely(g)
id <- tkplot(g, layout=lay)
canvas <- tk_canvas(id)
tcltk::tkpostscript(canvas, file="./output.eps")
tk_close(id)
g <- erdoss.renyi.game(n = 100, p.or.m = 0.04)
lo <- layout.fruchterman.reingold(net, repulserad = vcount(net)^2.8,
area = vcount(net)^2.3, niter = 1000)
plot(net, layout = lo, vertex.size = 3, vertex.frame.color = NULL,
vertex.label.dist = 0.5, vertex.label.cex = 0.7, edge.width = 0.5)
lo <- layout.fruchterman.reingold(net, repulserad = vcount(net)^2.8,
area = vcount(net)^2.3, niter = 1000)
plot(net, vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout = lo, vertex.size = 3, vertex.frame.color = NULL,
vertex.label.dist = 0.5, vertex.label.cex = 0.7, edge.width = 0.5)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*30.0,
vertex.color="white", vertex.label.color="black", vertex.size=25,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*30.0,
vertex.color="white", vertex.label.color="black", vertex.size=3,
edge.color="black", edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*30.0,
vertex.color="white", vertex.label.color="black", vertex.size=3,
edge.color="black", vertex.label.dist = 0.5, edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
g <- erdoss.renyi.game(n = 100, p.or.m = 0.04)
lo <- layout.fruchterman.reingold(net, repulserad = vcount(net)^2.8,
area = vcount(net)^2.3, niter = 1000)
plot(net, vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout = lo, vertex.size = 3, vertex.frame.color = NULL,
vertex.label.dist = 0.5, vertex.label.cex = 0.7,  vertex.label.color="black",
edge.color="black", edge.width = 0.5)
net=graph.adjacency(m,mode="directed",weighted=TRUE,diag=FALSE)
lo <- layout.fruchterman.reingold(net, repulserad = vcount(net)^2.8,
area = vcount(net)^2.3, niter = 1000)
plot(net, vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout = lo, vertex.size = 3, vertex.frame.color = NULL,
vertex.label.dist = 0.5, vertex.label.cex = 0.7,  vertex.label.color="black",
edge.color="black", , edge.arrow.size=0.5, edge.width = 0.5)
lo <- layout.fruchterman.reingold(net, repulserad = vcount(net)^2.8,
area = vcount(net)^2.3, niter = 1000)
plot(net, vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout = lo, vertex.size = 3, vertex.frame.color = NULL,
vertex.label.dist = 1, vertex.label.cex = 0.7,  vertex.label.color="black",
edge.color="black", edge.arrow.size=0.5, edge.width = 0.5)
lo <- layout.fruchterman.reingold(net, repulserad = vcount(net)^2.8,
area = vcount(net)^2.3, niter = 1000)
plot(net, vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout = lo, vertex.size = 3, vertex.frame.color = NULL,
vertex.label.dist = 1, vertex.label.cex = 0.7,  vertex.label.color="black",
edge.color="black", edge.arrow.size=0.5, edge.width = 0.5)
title(main = metric_labels[metric_i])
net=graph.adjacency(m,mode="directed",weighted=TRUE,diag=FALSE)
lo <- layout.fruchterman.reingold(net, repulserad = vcount(net)^2.8,
area = vcount(net)^2.3, niter = 1000)
plot(net, vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout = lo, vertex.size = 3, vertex.frame.color = NULL,
vertex.label.dist = 1, vertex.label.cex = 0.7,  vertex.label.color="black",
edge.color="black", edge.arrow.size=0.5, edge.width = 0.5)
#  plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*30.0, vertex.color="white", vertex.label.color="black", vertex.size=3, edge.color="black", vertex.label.dist = 0.5, edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
title(main = metric_labels[metric_i])
plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*30.0, vertex.color="white", vertex.label.color="black", vertex.size=3, edge.color="black", vertex.label.dist = 0.5, edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
lo <- layout.fruchterman.reingold(net, repulserad = vcount(net)^2.8,
area = vcount(net)^2.3, niter = 1000)
plot(net, vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout = lo, vertex.size = 5, vertex.frame.color = NULL,
vertex.label.dist = 1, vertex.label.cex = 0.7,  vertex.label.color="black",
edge.color="black", edge.arrow.size=0.5, edge.width = 0.5, edge.label = edge_val)
lo <- layout.fruchterman.reingold(net, repulserad = vcount(net)^2.8,
area = vcount(net)^2.3, niter = 1000)
plot(net, vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout = lo, vertex.size = 5, vertex.frame.color = NULL,
vertex.label.dist = 1, vertex.label.cex = 0.7,  vertex.label.color="black",
edge.color="black", edge.arrow.size=0.5, edge.width = 0.5, edge.label = edge_val, edge.label.cex=0.7)
library(igraph)
for(metric_i in 1:length(accuracy_metrics)){
print(accuracy_metrics[metric_i])
if(accuracy_metrics[metric_i] == "predRange"){
next
}
selectedData <- sig_bs[sig_bs$metric == metric_labels[metric_i],]
m <- matrix(0, nrow = length(models), ncol = length(models), byrow = FALSE)
colnames(m) <- names(models)
rownames(m) <- names(models)
for(i in 1:nrow(selectedData)){
if(selectedData$BH_p_value[i] < 0.05){
if(selectedData$direction[i] == "+"){
m[as.character(selectedData$model1[i]), as.character(selectedData$model2[i])] = round(selectedData$BH_p_value[i], 3)
}else if(selectedData$direction[i] == "-"){
m[as.character(selectedData$model2[i]), as.character(selectedData$model1[i])] = round(selectedData$BH_p_value[i], 3)
}
}
}
edge_val <- c()
# if A -> B -> C, remove edge A -> C
for(i in 1:length(models)){
for(j in 1:length(models)){
if(m[i,j] != 0){
edge_val <- c(edge_val, m[i,j])
for(k in 1:length(models)){
if(m[j,k] != 0)
m[i,k] = 0
}
}
}
}
#plot the directed graph
model_mean <- matrix(0, nrow = length(models), byrow = FALSE)
rownames(model_mean) <- names(models)
colnames(model_mean) <- "mean"
for(i in 1:nrow(selectedData)){
model_mean[which(rownames(model_mean) == selectedData[i,]$model1)] = round(selectedData[i,]$model1_mean, 3)
model_mean[which(rownames(model_mean) == selectedData[i,]$model2)] = round(selectedData[i,]$model2_mean, 3)
}
net=graph.adjacency(m,mode="directed",weighted=TRUE,diag=FALSE)
lo <- layout.fruchterman.reingold(net, repulserad = vcount(net)^2.8,
area = vcount(net)^2.3, niter = 1000)
plot(net, vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout = lo, vertex.size = 5, vertex.frame.color = NULL,
vertex.label.dist = 1, vertex.label.cex = 0.7,  vertex.label.color="black",
edge.color="black", edge.arrow.size=0.5, edge.width = 0.5, edge.label = edge_val, edge.label.cex=0.7)
#plot.igraph(net,vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout=layout.fruchterman.reingold(net)*30.0, vertex.color="white", vertex.label.color="black", vertex.size=3, edge.color="black", vertex.label.dist = 0.5, edge.label = edge_val, edge.width=3, edge.arrow.size=0.5, edge.arrow.width=1.2)
title(main = metric_labels[metric_i])
}
net=graph.adjacency(m,mode="directed",weighted=TRUE,diag=FALSE)
lo <- layout.fruchterman.reingold(net, niter = 1000)
plot(net, vertex.label=paste(V(net)$name, model_mean[which(rownames(model_mean) == V(net)$name)], sep = " : "), layout = lo, vertex.size = 5, vertex.frame.color = NULL,
vertex.label.dist = 1, vertex.label.cex = 0.7,  vertex.label.color="black",
edge.color="black", edge.arrow.size=0.5, edge.width = 0.5, edge.label = edge_val, edge.label.cex=0.7)
save.image("D:/ResearchSpace/ResearchProjects/UMLx/data/GitAndroidAnalysis/accuracy_analysis2/7-27.RData")
=======
>>>>>>> 0ee63dc8d7f46ced13faa9d30cddee827ccacaed
