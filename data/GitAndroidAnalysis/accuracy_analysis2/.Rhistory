})
#the prior model fit
priorModel <- priorFit(regressionData)
prior_validationResults <- crossValidate(regressionData, k, priorFit, function(priorModel, testData) {
predictedVals <- predict(priorModel, data.frame(transactionSum = priorTranSum(testData)))
names(predictedVals) <- rownames(testData)
predictedVals
})
searchResults[[i]] <- list(
bayesModel = bayesianModel,
bayesModelAccuracyMeasure = bm_validationResults,
priorModel = priorModel,
priorModelAccuracyMeasure = prior_validationResults,
regressionModel = regressionModel,
regressionModelAccuracyMeasure = reg_validationResults,
regressionData = regressionData
)
}
searchResults
}
#models1 = models
#register the model into the models list with the hyper parameters returned from  the "trainsaction_based_model" function
#transaction_models1 <- transaction_models
transaction_models <- trainsaction_based_model(modelData)
run_metropolis_MCMC <- function(regressionData, N, priorB, varianceMatrix, effortAdj){
# run metropolis-hasting algorithm to simulate the posterior probability
#
# Args:
#   regressionData: the classified transactions
#   N: the number of runs of simulation
#   priorB: the prior expected value of weights
#   varianceMatrix: the variance matrix for the weights
#   effortAdj: the prior effort adjustment factor
#
# Returns:
#   the simulated posterior joint distribution of the parameters
#regressionData <- regressionData
#N <- 10000
#priorB <- means
#varianceMatrix <- covar
chain = matrix(nrow=N+1, ncol=2*length(priorB)+2)
colnames(chain) <- c(names(priorB), paste(names(priorB), "sigma", sep="_"), "effortAdj", "sd")
chain[1, "effortAdj"] <- effortAdj['mean']
chain[1, "sd"] <- 10
chain[1, names(priorB)] <- priorB
sigma <- c(0.1)
if(length(priorB)>1){
for (i in 2:length(priorB)) {
sigma <- c(sigma, 1/5* (abs(priorB[i] - priorB[i - 1]))+0.1)
}
}
chain[1, paste(names(priorB), "sigma", sep="_")] = sigma
for (i in 1:N){
proposal = proposalfunction(chain[i,names(priorB)], chain[i,"effortAdj"], chain[i, "sd"])
#proposal = sample
`%ni%` <- Negate(`%in%`)
update <- posterior(proposal, priorB, varianceMatrix, effortAdj['mean'], effortAdj['var'], regressionData[ , !(colnames(regressionData) %in% c("Effort"))], regressionData[,c("Effort")])
postP <- posterior(chain[i,], priorB, varianceMatrix, effortAdj['mean'], effortAdj['var'], regressionData[ , !(colnames(regressionData) %in% c("Effort"))], regressionData[,c("Effort")])
probab = min(c(1, exp(update + proposalProbability(chain[i,], proposal) - postP - proposalProbability(proposal, chain[i, ]))))
#the better way of calculating the acceptance rate
acceptance = c()
if(is.na(probab) == FALSE & runif(1) < probab){
chain[i+1,] = proposal
#print("accept")
acceptance = c(acceptance, 1)
}else{
chain[i+1,] = chain[i,]
#print("not accept")
acceptance = c(acceptance, 0)
}
}
print(paste("acceptance rate:", sum(acceptance)/N))
return(chain)
}
run_metropolis_MCMC <- function(regressionData, N, priorB, varianceMatrix, effortAdj){
# run metropolis-hasting algorithm to simulate the posterior probability
#
# Args:
#   regressionData: the classified transactions
#   N: the number of runs of simulation
#   priorB: the prior expected value of weights
#   varianceMatrix: the variance matrix for the weights
#   effortAdj: the prior effort adjustment factor
#
# Returns:
#   the simulated posterior joint distribution of the parameters
#regressionData <- regressionData
#N <- 10000
#priorB <- means
#varianceMatrix <- covar
chain = matrix(nrow=N+1, ncol=2*length(priorB)+2)
colnames(chain) <- c(names(priorB), paste(names(priorB), "sigma", sep="_"), "effortAdj", "sd")
chain[1, "effortAdj"] <- effortAdj['mean']
chain[1, "sd"] <- 10
chain[1, names(priorB)] <- priorB
sigma <- c(0.1)
if(length(priorB)>1){
for (i in 2:length(priorB)) {
sigma <- c(sigma, 1/5* (abs(priorB[i] - priorB[i - 1]))+0.1)
}
}
chain[1, paste(names(priorB), "sigma", sep="_")] = sigma
for (i in 1:N){
proposal = proposalfunction(chain[i,names(priorB)], chain[i,"effortAdj"], chain[i, "sd"])
#proposal = sample
`%ni%` <- Negate(`%in%`)
update <- posterior(proposal, priorB, varianceMatrix, effortAdj['mean'], effortAdj['var'], regressionData[ , !(colnames(regressionData) %in% c("Effort"))], regressionData[,c("Effort")])
postP <- posterior(chain[i,], priorB, varianceMatrix, effortAdj['mean'], effortAdj['var'], regressionData[ , !(colnames(regressionData) %in% c("Effort"))], regressionData[,c("Effort")])
probab = min(c(1, exp(update + proposalProbability(chain[i,], proposal) - postP - proposalProbability(proposal, chain[i, ]))))
#the better way of calculating the acceptance rate
acceptance = c()
if(is.na(probab) == FALSE & runif(1) < probab){
chain[i+1,] = proposal
#print("accept")
acceptance = c(acceptance, 1)
}else{
chain[i+1,] = chain[i,]
#print("not accept")
acceptance = c(acceptance, 0)
}
}
print(paste("acceptance rate:", sum(acceptance)/N))
return(chain)
}
run_metropolis_MCMC <- function(regressionData, N, priorB, varianceMatrix, effortAdj){
# run metropolis-hasting algorithm to simulate the posterior probability
#
# Args:
#   regressionData: the classified transactions
#   N: the number of runs of simulation
#   priorB: the prior expected value of weights
#   varianceMatrix: the variance matrix for the weights
#   effortAdj: the prior effort adjustment factor
#
# Returns:
#   the simulated posterior joint distribution of the parameters
#regressionData <- regressionData
#N <- 10000
#priorB <- means
#varianceMatrix <- covar
chain = matrix(nrow=N+1, ncol=2*length(priorB)+2)
colnames(chain) <- c(names(priorB), paste(names(priorB), "sigma", sep="_"), "effortAdj", "sd")
chain[1, "effortAdj"] <- effortAdj['mean']
chain[1, "sd"] <- 10
chain[1, names(priorB)] <- priorB
sigma <- c(0.1)
if(length(priorB)>1){
for (i in 2:length(priorB)) {
sigma <- c(sigma, 1/5* (abs(priorB[i] - priorB[i - 1]))+0.1)
}
}
chain[1, paste(names(priorB), "sigma", sep="_")] = sigma
for (i in 1:N){
proposal = proposalfunction(chain[i,names(priorB)], chain[i,"effortAdj"], chain[i, "sd"])
#proposal = sample
`%ni%` <- Negate(`%in%`)
update <- posterior(proposal, priorB, varianceMatrix, effortAdj['mean'], effortAdj['var'], regressionData[ , !(colnames(regressionData) %in% c("Effort"))], regressionData[,c("Effort")])
postP <- posterior(chain[i,], priorB, varianceMatrix, effortAdj['mean'], effortAdj['var'], regressionData[ , !(colnames(regressionData) %in% c("Effort"))], regressionData[,c("Effort")])
probab = min(c(1, exp(update + proposalProbability(chain[i,], proposal) - postP - proposalProbability(proposal, chain[i, ]))))
#the better way of calculating the acceptance rate
acceptance = c()
if(is.na(probab) == FALSE & runif(1) < probab){
chain[i+1,] = proposal
#print("accept")
acceptance = c(acceptance, 1)
}else{
chain[i+1,] = chain[i,]
#print("not accept")
acceptance = c(acceptance, 0)
}
}
print(paste("acceptance rate:", sum(acceptance)/N))
return(chain)
}
performSearch <- function(n, dataset, parameters = c("TL", "TD", "DETs"), k = 5) {
# Performs search for the optimal number of bins and weights to apply to each
# bin through linear regression.
#
# Args:
#   n: Specifies up to how many bins per parameter to search.
#   folder: Folder containg all the transaction analytics data to analyze.
#   effortData: a data frame containing effort data corresponding to each of
#               the files contained in the folder argument. Rows must be named
#               the same as the filename and effort column should be named "Effort".
#   parameters: A vector of which parameters to analyze. Ex. "TL", "TD", "DETs". When the parameters is an empty array, just apply linear regression on number of transactions.
#   k: How many folds to use for k-fold cross validation.
#
# Returns:
#   A list in which the ith index gives the results of the search for i bins.
#n = 6
#dataset = modelData
#parameters = c("TL", "TD", "DETs")
#k = 5
#dataset <- modelData
#cachedTransactionFiles <- list()
#load transaction data from the datasheet
transactionData <- loadTransactionData(dataset)
#distParams = list();
#distParams[['TL']] = list(shape=6.543586, rate=1.160249);
#distParams[['TD']] = list(shape=3.6492150, rate=0.6985361);
#distParams[['DETs']] = list(shape=1.6647412, rate=0.1691911);
#Ks parameteric test
#distParams = list();
#print(combinedData[,])
#hist(combinedData[combinedData$TL < 20 & combinedData$TL > 2,"TL"])
#hist(combinedData[combinedData$TD < 100, "TD"])
#hist(combinedData[combinedData$DETs < 10, "DETs"])
#n <- 5
#quantiles <- seq(1/n, 1 - (1/n), 1/n)
#print(classIntervals(combinedData[combinedData$DETs < 30, "DETs"], 6, style = 'quantile'))
#print(classIntervals(combinedData[,"TL"], 4)$brks)
#print(quantize(combinedData[,"TL"], quantiles))
#distParams[['TL']] = (combinedData[combinedData$TL < 20 & combinedData$TL > 2,"TL"]);
#distParams[['TD']] = distFit(combinedData[combinedData$TD < 1000, "TD"]);
#distParams[['DETs']] = distFit(combinedData[combinedData$DETs < 10, "DETs"]);
#paramAvg <- if (length(parameters) == 1) mean(combinedData[, parameters]) else colMeans(combinedData[, parameters])
#paramSD <- if (length(parameters) == 1) sd(combinedData[, parameters]) else apply(combinedData[, parameters], 2, sd)
if(length(parameters) == 0){
n = 1
}
searchResults <- list()
for (i in seq(1,n)) {
cutPoints <- matrix(NA, nrow = length(parameters), ncol = i + 1)
rownames(cutPoints) <- parameters
for (p in parameters) {
cutPoints[p, ] <- discretize(transactionData$combined[,p], i)
}
#generate classified regression data
regressionData <- generateRegressionData(transactionData$projects, cutPoints, transactionData$effort, transactionData$transactionFiles)
`%ni%` <- Negate(`%in%`)
paramVals <- bayesfit(regressionData, 10000, 500)
bayesianModel = list()
bayesianModel$weights = subset(paramVals, select = colnames(regressionData) %ni% c("Effort", "sd"))
bayesianModel$effortAdj = paramVals[,"effortAdj"]
bayesianModel$sd = paramVals[,"sd"]
bayesianModel$cuts <- cutPoints
bm_validationResults <- crossValidate(regressionData, k, function(trainData) bayesfit(trainData, 10000, 500), predict.blm)
#print(bm_validationResults)
#the regression model fit
regressionModel <- lm(Effort ~ . - 1, as.data.frame(regressionData));
reg_validationResults <- crossValidate(regressionData, k,function(trainData) lm(Effort ~ . - 1, as.data.frame(trainData)), function(lm.fit, testData) {
predictedVals <- predict(lm.fit, testData)
names(predictedVals) <- rownames(testData)
#print(rownames(testData))
#print(predictedVals)
predictedVals
})
#the prior model fit
priorModel <- priorFit(regressionData)
prior_validationResults <- crossValidate(regressionData, k, priorFit, function(priorModel, testData) {
predictedVals <- predict(priorModel, data.frame(transactionSum = priorTranSum(testData)))
names(predictedVals) <- rownames(testData)
predictedVals
})
searchResults[[i]] <- list(
bayesModel = bayesianModel,
bayesModelAccuracyMeasure = bm_validationResults,
priorModel = priorModel,
priorModelAccuracyMeasure = prior_validationResults,
regressionModel = regressionModel,
regressionModelAccuracyMeasure = reg_validationResults,
regressionData = regressionData
)
}
searchResults
}
performSearch <- function(n, dataset, parameters = c("TL", "TD", "DETs"), k = 5) {
# Performs search for the optimal number of bins and weights to apply to each
# bin through linear regression.
#
# Args:
#   n: Specifies up to how many bins per parameter to search.
#   folder: Folder containg all the transaction analytics data to analyze.
#   effortData: a data frame containing effort data corresponding to each of
#               the files contained in the folder argument. Rows must be named
#               the same as the filename and effort column should be named "Effort".
#   parameters: A vector of which parameters to analyze. Ex. "TL", "TD", "DETs". When the parameters is an empty array, just apply linear regression on number of transactions.
#   k: How many folds to use for k-fold cross validation.
#
# Returns:
#   A list in which the ith index gives the results of the search for i bins.
#n = 6
#dataset = modelData
#parameters = c("TL", "TD", "DETs")
#k = 5
#dataset <- modelData
#cachedTransactionFiles <- list()
#load transaction data from the datasheet
transactionData <- loadTransactionData(dataset)
#distParams = list();
#distParams[['TL']] = list(shape=6.543586, rate=1.160249);
#distParams[['TD']] = list(shape=3.6492150, rate=0.6985361);
#distParams[['DETs']] = list(shape=1.6647412, rate=0.1691911);
#Ks parameteric test
#distParams = list();
#print(combinedData[,])
#hist(combinedData[combinedData$TL < 20 & combinedData$TL > 2,"TL"])
#hist(combinedData[combinedData$TD < 100, "TD"])
#hist(combinedData[combinedData$DETs < 10, "DETs"])
#n <- 5
#quantiles <- seq(1/n, 1 - (1/n), 1/n)
#print(classIntervals(combinedData[combinedData$DETs < 30, "DETs"], 6, style = 'quantile'))
#print(classIntervals(combinedData[,"TL"], 4)$brks)
#print(quantize(combinedData[,"TL"], quantiles))
#distParams[['TL']] = (combinedData[combinedData$TL < 20 & combinedData$TL > 2,"TL"]);
#distParams[['TD']] = distFit(combinedData[combinedData$TD < 1000, "TD"]);
#distParams[['DETs']] = distFit(combinedData[combinedData$DETs < 10, "DETs"]);
#paramAvg <- if (length(parameters) == 1) mean(combinedData[, parameters]) else colMeans(combinedData[, parameters])
#paramSD <- if (length(parameters) == 1) sd(combinedData[, parameters]) else apply(combinedData[, parameters], 2, sd)
if(length(parameters) == 0){
n = 1
}
searchResults <- list()
for (i in seq(1,n)) {
cutPoints <- matrix(NA, nrow = length(parameters), ncol = i + 1)
rownames(cutPoints) <- parameters
for (p in parameters) {
cutPoints[p, ] <- discretize(transactionData$combined[,p], i)
}
#generate classified regression data
regressionData <- generateRegressionData(transactionData$projects, cutPoints, transactionData$effort, transactionData$transactionFiles)
`%ni%` <- Negate(`%in%`)
paramVals <- bayesfit(regressionData, 100, 50)
bayesianModel = list()
bayesianModel$weights = subset(paramVals, select = colnames(regressionData) %ni% c("Effort", "sd"))
bayesianModel$effortAdj = paramVals[,"effortAdj"]
bayesianModel$sd = paramVals[,"sd"]
bayesianModel$cuts <- cutPoints
bm_validationResults <- crossValidate(regressionData, k, function(trainData) bayesfit(trainData, 100, 50), predict.blm)
#print(bm_validationResults)
#the regression model fit
regressionModel <- lm(Effort ~ . - 1, as.data.frame(regressionData));
reg_validationResults <- crossValidate(regressionData, k,function(trainData) lm(Effort ~ . - 1, as.data.frame(trainData)), function(lm.fit, testData) {
predictedVals <- predict(lm.fit, testData)
names(predictedVals) <- rownames(testData)
#print(rownames(testData))
#print(predictedVals)
predictedVals
})
#the prior model fit
priorModel <- priorFit(regressionData)
prior_validationResults <- crossValidate(regressionData, k, priorFit, function(priorModel, testData) {
predictedVals <- predict(priorModel, data.frame(transactionSum = priorTranSum(testData)))
names(predictedVals) <- rownames(testData)
predictedVals
})
searchResults[[i]] <- list(
bayesModel = bayesianModel,
bayesModelAccuracyMeasure = bm_validationResults,
priorModel = priorModel,
priorModelAccuracyMeasure = prior_validationResults,
regressionModel = regressionModel,
regressionModelAccuracyMeasure = reg_validationResults,
regressionData = regressionData
)
}
searchResults
}
#models1 = models
#register the model into the models list with the hyper parameters returned from  the "trainsaction_based_model" function
#transaction_models1 <- transaction_models
transaction_models <- trainsaction_based_model(modelData)
run_metropolis_MCMC <- function(regressionData, N, priorB, varianceMatrix, effortAdj){
# run metropolis-hasting algorithm to simulate the posterior probability
#
# Args:
#   regressionData: the classified transactions
#   N: the number of runs of simulation
#   priorB: the prior expected value of weights
#   varianceMatrix: the variance matrix for the weights
#   effortAdj: the prior effort adjustment factor
#
# Returns:
#   the simulated posterior joint distribution of the parameters
#regressionData <- regressionData
#N <- 10000
#priorB <- means
#varianceMatrix <- covar
chain = matrix(nrow=N+1, ncol=2*length(priorB)+2)
colnames(chain) <- c(names(priorB), paste(names(priorB), "sigma", sep="_"), "effortAdj", "sd")
chain[1, "effortAdj"] <- effortAdj['mean']
chain[1, "sd"] <- 10
chain[1, names(priorB)] <- priorB
sigma <- c(0.1)
if(length(priorB)>1){
for (i in 2:length(priorB)) {
sigma <- c(sigma, 1/5* (abs(priorB[i] - priorB[i - 1]))+0.1)
}
}
chain[1, paste(names(priorB), "sigma", sep="_")] = sigma
for (i in 1:N){
proposal = proposalfunction(chain[i,names(priorB)], chain[i,"effortAdj"], chain[i, "sd"])
#proposal = sample
`%ni%` <- Negate(`%in%`)
update <- posterior(proposal, priorB, varianceMatrix, effortAdj['mean'], effortAdj['var'], regressionData[ , !(colnames(regressionData) %in% c("Effort"))], regressionData[,c("Effort")])
postP <- posterior(chain[i,], priorB, varianceMatrix, effortAdj['mean'], effortAdj['var'], regressionData[ , !(colnames(regressionData) %in% c("Effort"))], regressionData[,c("Effort")])
probab = min(c(1, exp(update + proposalProbability(chain[i,], proposal) - postP - proposalProbability(proposal, chain[i, ]))))
#the better way of calculating the acceptance rate
acceptance = c()
if(is.na(probab) == FALSE & runif(1) < probab){
chain[i+1,] = proposal
#print("accept")
acceptance = c(acceptance, 1)
}else{
chain[i+1,] = chain[i,]
#print("not accept")
acceptance = c(acceptance, 0)
}
}
#print(paste("acceptance rate:", sum(acceptance)/N))
return(chain)
}
#models1 = models
#register the model into the models list with the hyper parameters returned from  the "trainsaction_based_model" function
#transaction_models1 <- transaction_models
transaction_models <- trainsaction_based_model(modelData)
performSearch <- function(n, dataset, parameters = c("TL", "TD", "DETs"), k = 5) {
# Performs search for the optimal number of bins and weights to apply to each
# bin through linear regression.
#
# Args:
#   n: Specifies up to how many bins per parameter to search.
#   folder: Folder containg all the transaction analytics data to analyze.
#   effortData: a data frame containing effort data corresponding to each of
#               the files contained in the folder argument. Rows must be named
#               the same as the filename and effort column should be named "Effort".
#   parameters: A vector of which parameters to analyze. Ex. "TL", "TD", "DETs". When the parameters is an empty array, just apply linear regression on number of transactions.
#   k: How many folds to use for k-fold cross validation.
#
# Returns:
#   A list in which the ith index gives the results of the search for i bins.
#n = 6
#dataset = modelData
#parameters = c("TL", "TD", "DETs")
#k = 5
#dataset <- modelData
#cachedTransactionFiles <- list()
#load transaction data from the datasheet
transactionData <- loadTransactionData(dataset)
#distParams = list();
#distParams[['TL']] = list(shape=6.543586, rate=1.160249);
#distParams[['TD']] = list(shape=3.6492150, rate=0.6985361);
#distParams[['DETs']] = list(shape=1.6647412, rate=0.1691911);
#Ks parameteric test
#distParams = list();
#print(combinedData[,])
#hist(combinedData[combinedData$TL < 20 & combinedData$TL > 2,"TL"])
#hist(combinedData[combinedData$TD < 100, "TD"])
#hist(combinedData[combinedData$DETs < 10, "DETs"])
#n <- 5
#quantiles <- seq(1/n, 1 - (1/n), 1/n)
#print(classIntervals(combinedData[combinedData$DETs < 30, "DETs"], 6, style = 'quantile'))
#print(classIntervals(combinedData[,"TL"], 4)$brks)
#print(quantize(combinedData[,"TL"], quantiles))
#distParams[['TL']] = (combinedData[combinedData$TL < 20 & combinedData$TL > 2,"TL"]);
#distParams[['TD']] = distFit(combinedData[combinedData$TD < 1000, "TD"]);
#distParams[['DETs']] = distFit(combinedData[combinedData$DETs < 10, "DETs"]);
#paramAvg <- if (length(parameters) == 1) mean(combinedData[, parameters]) else colMeans(combinedData[, parameters])
#paramSD <- if (length(parameters) == 1) sd(combinedData[, parameters]) else apply(combinedData[, parameters], 2, sd)
if(length(parameters) == 0){
n = 1
}
searchResults <- list()
for (i in seq(1,n)) {
cutPoints <- matrix(NA, nrow = length(parameters), ncol = i + 1)
rownames(cutPoints) <- parameters
for (p in parameters) {
cutPoints[p, ] <- discretize(transactionData$combined[,p], i)
}
#generate classified regression data
regressionData <- generateRegressionData(transactionData$projects, cutPoints, transactionData$effort, transactionData$transactionFiles)
`%ni%` <- Negate(`%in%`)
paramVals <- bayesfit(regressionData, 100000, 500)
bayesianModel = list()
bayesianModel$weights = subset(paramVals, select = colnames(regressionData) %ni% c("Effort", "sd"))
bayesianModel$effortAdj = paramVals[,"effortAdj"]
bayesianModel$sd = paramVals[,"sd"]
bayesianModel$cuts <- cutPoints
bm_validationResults <- crossValidate(regressionData, k, function(trainData) bayesfit(trainData, 100000, 500), predict.blm)
#print(bm_validationResults)
#the regression model fit
regressionModel <- lm(Effort ~ . - 1, as.data.frame(regressionData));
reg_validationResults <- crossValidate(regressionData, k,function(trainData) lm(Effort ~ . - 1, as.data.frame(trainData)), function(lm.fit, testData) {
predictedVals <- predict(lm.fit, testData)
names(predictedVals) <- rownames(testData)
#print(rownames(testData))
#print(predictedVals)
predictedVals
})
#the prior model fit
priorModel <- priorFit(regressionData)
prior_validationResults <- crossValidate(regressionData, k, priorFit, function(priorModel, testData) {
predictedVals <- predict(priorModel, data.frame(transactionSum = priorTranSum(testData)))
names(predictedVals) <- rownames(testData)
predictedVals
})
searchResults[[i]] <- list(
bayesModel = bayesianModel,
bayesModelAccuracyMeasure = bm_validationResults,
priorModel = priorModel,
priorModelAccuracyMeasure = prior_validationResults,
regressionModel = regressionModel,
regressionModelAccuracyMeasure = reg_validationResults,
regressionData = regressionData
)
}
searchResults
}
#models1 = models
#register the model into the models list with the hyper parameters returned from  the "trainsaction_based_model" function
#transaction_models1 <- transaction_models
transaction_models <- trainsaction_based_model(modelData)
