user_info <- GET(user_url, authenticate(user, pw))
user_info = as.character(user_info)
email = stringr::str_split(user_info, "email", 2)[[1]][2]
email = stringr::str_split(email, "name", 2)[[1]][1]
email = stringr::str_split(email, "\": \"", 2)[[1]][2]
email = stringr::str_split(email, "\",\n", 2)[[1]][1]
name = as.character(contributors[[1]][k])
if(is.na(email)==FALSE){
sub_line <- data.frame(name = name, email = email,repo_name = contributors[["repo_name"]][k])
line <- rbind(line,sub_line)
email = NA
print(sub_line)
}
}
out <- rbind(out, line)
}
write.xlsx(out, "email.xlsx")
# import libraries
library(xlsx)
library(jsonlite)
library(httr)
library(stringr)
# local functions
getTotalPages <- function(linkHeaderStr){
matched <-
stringr::str_match(linkHeaderStr, "page=(\\d+)>; rel=\\\"last\\\"")
as.integer((matched[ ,2]))
}
rbind.match.columns <- function(input1, input2) {
n.input1 <- ncol(input1)
n.input2 <- ncol(input2)
if (n.input2 < n.input1) {
TF.names <- which(names(input2) %in% names(input1))
column.names <- names(input2[, TF.names])
} else {
TF.names <- which(names(input1) %in% names(input2))
column.names <- names(input1[, TF.names])
}
return(rbind(input1[, column.names], input2[, column.names]))
}
# set user-agent
user = "flyqk"
pw = "qk@github/910304"
# import urls
data = read.xlsx("repos.xlsx",sheetName="data",header=T)
data[i,1] = as.character(data[i,1])
data[i,2] = as.character(data[i,2])
# read email segment and return data
out <- data.frame()
for(i in 2:2){
repo_name = as.character(data[i,1])
repo_url = data[i,2]
print(paste("## ",repo_name, " ##"))
# find contriutor list
contributors <- list()
url = paste("https://api.github.com/repos", unlist(strsplit(as.character(repo_url), "https://github.com/"))[2], sep="/", collapse=NULL)
info <- GET(paste(url, "/contributors?page=1", sep=''), authenticate(user, pw))
pages <- getTotalPages(info$headers$link)
if(length(pages)>0){
print(paste(i, "if"))
for(k in seq(1:pages)){
resp <- GET(paste(url, "/contributors?page=", k, sep=''), authenticate(user, pw))
currentPage <- fromJSON(content(resp, "text"), flatten = TRUE)
currentPage$repo_name <- repo_name
contributors[[k]] <- currentPage
}
}else{
print(paste(i, "else"))
resp <- GET(paste(url, "/contributors", sep=''), authenticate(user, pw))
currentPage <- fromJSON(content(resp, "text"), flatten = TRUE)
currentPage$repo_name <- repo_name
contributors[[i]] <- currentPage
}
contributors <- rbind_pages(contributors)
contributors_info = contributors[ , 1]
# find user info
max = 200
line <- data.frame(name=c(), email=c(), contributions = c(), repo_name=c())
for(k in 1:nrow(contributors[1])){
user_url = paste("https://api.github.com/users", contributors[k, 1], "events/public", sep="/")
print(user_url)
user_info <- GET(user_url, authenticate(user, pw))
user_info = as.character(user_info)
email = stringr::str_split(user_info, "email", 2)[[1]][2]
email = stringr::str_split(email, "name", 2)[[1]][1]
email = stringr::str_split(email, "\": \"", 2)[[1]][2]
email = stringr::str_split(email, "\",\n", 2)[[1]][1]
name = as.character(contributors[[1]][k])
if(is.na(email)==FALSE){
sub_line <- data.frame(name = name, email = email, contributions = contributors[["contributions"]][k], repo_name = contributors[["repo_name"]][k])
line <- rbind(line,sub_line)
email = NA
print(sub_line)
}
}
out <- rbind(out, line)
}
write.xlsx(out, "email.xlsx")
# import libraries
library(xlsx)
library(jsonlite)
library(httr)
library(stringr)
# local functions
getTotalPages <- function(linkHeaderStr){
matched <-
stringr::str_match(linkHeaderStr, "page=(\\d+)>; rel=\\\"last\\\"")
as.integer((matched[ ,2]))
}
rbind.match.columns <- function(input1, input2) {
n.input1 <- ncol(input1)
n.input2 <- ncol(input2)
if (n.input2 < n.input1) {
TF.names <- which(names(input2) %in% names(input1))
column.names <- names(input2[, TF.names])
} else {
TF.names <- which(names(input1) %in% names(input2))
column.names <- names(input1[, TF.names])
}
return(rbind(input1[, column.names], input2[, column.names]))
}
# set user-agent
user = "flyqk"
pw = "qk@github/910304"
# import urls
data = read.xlsx("repos.xlsx",sheetName="data",header=T)
data[i,1] = as.character(data[i,1])
data[i,2] = as.character(data[i,2])
# read email segment and return data
out <- data.frame()
for(i in 1:2){
repo_name = as.character(data[i,1])
repo_url = data[i,2]
print(paste("## ",repo_name, " ##"))
# find contriutor list
contributors <- list()
url = paste("https://api.github.com/repos", unlist(strsplit(as.character(repo_url), "https://github.com/"))[2], sep="/", collapse=NULL)
info <- GET(paste(url, "/contributors?page=1", sep=''), authenticate(user, pw))
pages <- getTotalPages(info$headers$link)
if(length(pages)>0){
print(paste(i, "if"))
for(k in seq(1:pages)){
resp <- GET(paste(url, "/contributors?page=", k, sep=''), authenticate(user, pw))
currentPage <- fromJSON(content(resp, "text"), flatten = TRUE)
currentPage$repo_name <- repo_name
contributors[[k]] <- currentPage
}
}else{
print(paste(i, "else"))
resp <- GET(paste(url, "/contributors", sep=''), authenticate(user, pw))
currentPage <- fromJSON(content(resp, "text"), flatten = TRUE)
currentPage$repo_name <- repo_name
contributors[[i]] <- currentPage
}
contributors <- rbind_pages(contributors)
contributors_info = contributors[ , 1]
# find user info
max = 200
line <- data.frame(name=c(), email=c(), contributions = c(), repo_name=c())
for(k in 1:nrow(contributors[1])){
user_url = paste("https://api.github.com/users", contributors[k, 1], "events/public", sep="/")
print(user_url)
user_info <- GET(user_url, authenticate(user, pw))
user_info = as.character(user_info)
email = stringr::str_split(user_info, "email", 2)[[1]][2]
email = stringr::str_split(email, "name", 2)[[1]][1]
email = stringr::str_split(email, "\": \"", 2)[[1]][2]
email = stringr::str_split(email, "\",\n", 2)[[1]][1]
name = as.character(contributors[[1]][k])
if(is.na(email)==FALSE){
sub_line <- data.frame(name = name, email = email, contributions = contributors[["contributions"]][k], repo_name = contributors[["repo_name"]][k])
line <- rbind(line,sub_line)
email = NA
print(sub_line)
}
}
out <- rbind(out, line)
}
write.xlsx(out, "email.xlsx")
# import libraries
library(xlsx)
library(jsonlite)
library(httr)
library(stringr)
# local functions
getTotalPages <- function(linkHeaderStr){
matched <-
stringr::str_match(linkHeaderStr, "page=(\\d+)>; rel=\\\"last\\\"")
as.integer((matched[ ,2]))
}
rbind.match.columns <- function(input1, input2) {
n.input1 <- ncol(input1)
n.input2 <- ncol(input2)
if (n.input2 < n.input1) {
TF.names <- which(names(input2) %in% names(input1))
column.names <- names(input2[, TF.names])
} else {
TF.names <- which(names(input1) %in% names(input2))
column.names <- names(input1[, TF.names])
}
return(rbind(input1[, column.names], input2[, column.names]))
}
# set user-agent
user = "flyqk"
pw = "qk@github/910304"
# import urls
data = read.xlsx("repos.xlsx",sheetName="data",header=T)
data[i,1] = as.character(data[i,1])
data[i,2] = as.character(data[i,2])
# read email segment and return data
out <- data.frame()
for(i in 3:nrow(data)){
repo_name = as.character(data[i,1])
repo_url = data[i,2]
print(paste("## ",repo_name, " ##"))
# find contriutor list
contributors <- list()
url = paste("https://api.github.com/repos", unlist(strsplit(as.character(repo_url), "https://github.com/"))[2], sep="/", collapse=NULL)
info <- GET(paste(url, "/contributors?page=1", sep=''), authenticate(user, pw))
pages <- getTotalPages(info$headers$link)
if(length(pages)>0){
print(paste(i, "if"))
for(k in seq(1:pages)){
resp <- GET(paste(url, "/contributors?page=", k, sep=''), authenticate(user, pw))
currentPage <- fromJSON(content(resp, "text"), flatten = TRUE)
currentPage$repo_name <- repo_name
contributors[[k]] <- currentPage
}
}else{
print(paste(i, "else"))
resp <- GET(paste(url, "/contributors", sep=''), authenticate(user, pw))
currentPage <- fromJSON(content(resp, "text"), flatten = TRUE)
currentPage$repo_name <- repo_name
contributors[[i]] <- currentPage
}
contributors <- rbind_pages(contributors)
contributors_info = contributors[ , 1]
# find user info
max = 200
line <- data.frame(name=c(), email=c(), contributions = c(), repo_name=c())
for(k in 1:nrow(contributors[1])){
user_url = paste("https://api.github.com/users", contributors[k, 1], "events/public", sep="/")
print(user_url)
user_info <- GET(user_url, authenticate(user, pw))
user_info = as.character(user_info)
email = stringr::str_split(user_info, "email", 2)[[1]][2]
email = stringr::str_split(email, "name", 2)[[1]][1]
email = stringr::str_split(email, "\": \"", 2)[[1]][2]
email = stringr::str_split(email, "\",\n", 2)[[1]][1]
name = as.character(contributors[[1]][k])
if(is.na(email)==FALSE){
sub_line <- data.frame(name = name, email = email, contributions = contributors[["contributions"]][k], repo_name = contributors[["repo_name"]][k])
line <- rbind(line,sub_line)
email = NA
print(sub_line)
}
}
out <- rbind(out, line)
}
write.xlsx(out, "email.xlsx")
View(contributors)
View(contributors)
# import libraries
library(xlsx)
library(jsonlite)
library(httr)
library(stringr)
# local functions
getTotalPages <- function(linkHeaderStr){
matched <-
stringr::str_match(linkHeaderStr, "page=(\\d+)>; rel=\\\"last\\\"")
as.integer((matched[ ,2]))
}
rbind.match.columns <- function(input1, input2) {
n.input1 <- ncol(input1)
n.input2 <- ncol(input2)
if (n.input2 < n.input1) {
TF.names <- which(names(input2) %in% names(input1))
column.names <- names(input2[, TF.names])
} else {
TF.names <- which(names(input1) %in% names(input2))
column.names <- names(input1[, TF.names])
}
return(rbind(input1[, column.names], input2[, column.names]))
}
# set user-agent
user = "flyqk"
pw = "qk@github/910304"
# import urls
data = read.xlsx("repos.xlsx",sheetName="data",header=T)
data[i,1] = as.character(data[i,1])
data[i,2] = as.character(data[i,2])
# read email segment and return data
out <- data.frame()
for(i in 49:nrow(data)){
repo_name = as.character(data[i,1])
repo_url = data[i,2]
print(paste("## ",repo_name, " ##"))
# find contriutor list
contributors <- list()
url = paste("https://api.github.com/repos", unlist(strsplit(as.character(repo_url), "https://github.com/"))[2], sep="/", collapse=NULL)
info <- GET(paste(url, "/contributors?page=1", sep=''), authenticate(user, pw))
pages <- getTotalPages(info$headers$link)
if(length(pages)>0){
print(paste(i, "if"))
for(k in seq(1:pages)){
resp <- GET(paste(url, "/contributors?page=", k, sep=''), authenticate(user, pw))
currentPage <- fromJSON(content(resp, "text"), flatten = TRUE)
currentPage$repo_name <- repo_name
contributors[[k]] <- currentPage
}
}else{
print(paste(i, "else"))
resp <- GET(paste(url, "/contributors", sep=''), authenticate(user, pw))
currentPage <- fromJSON(content(resp, "text"), flatten = TRUE)
currentPage$repo_name <- repo_name
contributors[[i]] <- currentPage
}
contributors <- rbind_pages(contributors)
contributors_info = contributors[ , 1]
# find user info
max = 200
line <- data.frame(name=c(), email=c(), contributions = c(), repo_name=c())
for(k in 1:nrow(contributors[1])){
user_url = paste("https://api.github.com/users", contributors[k, 1], "events/public", sep="/")
print(user_url)
user_info <- GET(user_url, authenticate(user, pw))
user_info = as.character(user_info)
email = stringr::str_split(user_info, "email", 2)[[1]][2]
email = stringr::str_split(email, "name", 2)[[1]][1]
email = stringr::str_split(email, "\": \"", 2)[[1]][2]
email = stringr::str_split(email, "\",\n", 2)[[1]][1]
name = as.character(contributors[[1]][k])
if(is.na(email)==FALSE){
sub_line <- data.frame(name = name, email = email, contributions = contributors[["contributions"]][k], repo_name = contributors[["repo_name"]][k])
line <- rbind(line,sub_line)
email = NA
print(sub_line)
}
}
out <- rbind(out, line)
}
write.xlsx(out, "email.xlsx")
View(contributors)
View(contributors)
# import libraries
library(xlsx)
library(jsonlite)
library(httr)
library(stringr)
# local functions
getTotalPages <- function(linkHeaderStr){
matched <-
stringr::str_match(linkHeaderStr, "page=(\\d+)>; rel=\\\"last\\\"")
as.integer((matched[ ,2]))
}
rbind.match.columns <- function(input1, input2) {
n.input1 <- ncol(input1)
n.input2 <- ncol(input2)
if (n.input2 < n.input1) {
TF.names <- which(names(input2) %in% names(input1))
column.names <- names(input2[, TF.names])
} else {
TF.names <- which(names(input1) %in% names(input2))
column.names <- names(input1[, TF.names])
}
return(rbind(input1[, column.names], input2[, column.names]))
}
# set user-agent
user = "flyqk"
pw = "qk@github/910304"
# import urls
data = read.xlsx("repos.xlsx",sheetName="data",header=T)
data[i,1] = as.character(data[i,1])
data[i,2] = as.character(data[i,2])
# read email segment and return data
out <- data.frame()
for(i in 63:nrow(data)){
repo_name = as.character(data[i,1])
repo_url = data[i,2]
print(paste("## ",repo_name, " ##"))
# find contriutor list
contributors <- list()
url = paste("https://api.github.com/repos", unlist(strsplit(as.character(repo_url), "https://github.com/"))[2], sep="/", collapse=NULL)
info <- GET(paste(url, "/contributors?page=1", sep=''), authenticate(user, pw))
pages <- getTotalPages(info$headers$link)
if(length(pages)>0){
print(paste(i, "if"))
for(k in seq(1:pages)){
resp <- GET(paste(url, "/contributors?page=", k, sep=''), authenticate(user, pw))
currentPage <- fromJSON(content(resp, "text"), flatten = TRUE)
currentPage$repo_name <- repo_name
contributors[[k]] <- currentPage
}
}else{
print(paste(i, "else"))
resp <- GET(paste(url, "/contributors", sep=''), authenticate(user, pw))
currentPage <- fromJSON(content(resp, "text"), flatten = TRUE)
currentPage$repo_name <- repo_name
contributors[[i]] <- currentPage
}
contributors <- rbind_pages(contributors)
contributors_info = contributors[ , 1]
# find user info
max = 200
line <- data.frame(name=c(), email=c(), contributions = c(), repo_name=c())
for(k in 1:nrow(contributors[1])){
user_url = paste("https://api.github.com/users", contributors[k, 1], "events/public", sep="/")
print(user_url)
user_info <- GET(user_url, authenticate(user, pw))
user_info = as.character(user_info)
email = stringr::str_split(user_info, "email", 2)[[1]][2]
email = stringr::str_split(email, "name", 2)[[1]][1]
email = stringr::str_split(email, "\": \"", 2)[[1]][2]
email = stringr::str_split(email, "\",\n", 2)[[1]][1]
name = as.character(contributors[[1]][k])
if(is.na(email)==FALSE){
sub_line <- data.frame(name = name, email = email, contributions = contributors[["contributions"]][k], repo_name = contributors[["repo_name"]][k])
line <- rbind(line,sub_line)
email = NA
print(sub_line)
}
}
out <- rbind(out, line)
}
write.xlsx(out, "email.xlsx")
source("stepwise_linear_model.R")
source("stepwise_linear_model.R")
models = list()
#intialize the step-wise learning model
models$step_lnr <- stepwise_linear_model()
#intialize the step-wise learning model
models$step_lnr <- stepwise_linear_model(modelData)
benchmarkResults <- modelBenchmark(models, modelData)
#The previous dataset
#modelData <- selectData("dsets/modelEvaluations-1-3.csv")
#The current dataset
modelData <- selectData("dsets/android_dataset_5_15.csv")
#intialize the step-wise learning model
models$step_lnr <- stepwise_linear_model(modelData)
benchmarkResults <- modelBenchmark(models, modelData)
benchmarkResults <- modelBenchmark(models, modelData)
model_names <- benchmarkResults$model_names
accuracy_metrics <- benchmarkResults$accuracy_metrics
#plot for the cross validation results
cvResults <- benchmarkResults$cvResults
avgPreds <- cvResults[["avgPreds"]]
avgPreds <- data.frame(avgPreds)
meltAvgPreds = melt(avgPreds, id.vars="Pred")
colnames(meltAvgPreds) <- c("Pred", "Method", "Value")
print("melt avg preds info")
ggplot(meltAvgPreds) + theme_bw() + geom_point(aes(x=Pred, y=Value, group=Method,color=Method),size=3)+ xlab("Relative Deviation (%)") +
ylab("Percentage of Estimates <= x%")+ theme(legend.position="bottom")
print("melt avg preds info as lines and smooth function")
ggplot(meltAvgPreds) + theme_bw() +
geom_line(aes(y=Value, x=Pred, group=Method,color=Method)) +
stat_smooth(aes(y=Value, x=Pred, group=Method,color=Method), method = lm, formula = y ~ poly(x, 10), se = FALSE)+ xlab("Relative Deviation (%)") +
ylab("Percentage of Estimates <= x%")+ theme(legend.position="bottom")
print("melt avg preds info as dots and smooth function")
ggplot(meltAvgPreds) + theme_bw() +
geom_point(aes(x=Pred, y=Value, group=Method,color=Method,shape=Method),size=1.5) +
scale_shape_manual(values=c(0,1,2,3,4,5,6,7,8,9,10))+
stat_smooth(aes(x=Pred, y=Value, group=Method,color=Method), method = lm, formula = y ~ poly(x, 10), se = FALSE)+ xlab("Relative Deviation (%)") +
ylab("Percentage of Estimates <= x%")+ theme(legend.position="bottom")
###plot for the bootstrapping results
bsRet <- benchmarkResults$bsResults
#bootstrappingSE(SWTIIIModelData, otherSizeMetricsData, model3, 10000, 0.83)
bsEstimations <- bsRet[['bsEstimations']]
iterResults <- bsRet[['iterResults']]
#save as csv
#write.csv(bsEstimations, file='bsEstimations.csv', quote=F, row.names = F)
#write.csv(iterResults, file='iterResults.csv', quote=F, row.names = F)
#read from csv
#bsEstimations <- read.csv('bsEstimations.csv')
#rownames(bsEstimations) <- c('lower','mean','upper')
#iterResults <- read.csv('iterResults.csv')
# plot bootstrapping results
model_labels <- c()
for(i in 1:length(models)){
for(j in 1:length(accuracy_metrics)){
model_labels = c(model_labels, names(models)[i])
}
}
metric_labels <- c()
for(i in 1:length(models)){
for(j in 1:length(accuracy_metrics)){
metric_labels = c(metric_labels, accuracy_metrics[j])
}
}
df <- data.frame(t(bsEstimations))
df$labels <- rownames(df)
df$model_labels <- model_labels
df$metric_labels <- metric_labels
for (i in 1:length(metric_labels)){
g = metric_labels[i]
selectedData <- df[df$metric_labels == g,]
p <- ggplot(selectedData, aes(x = labels, y = mean, ymin = lower, ymax = upper, fill = metric_labels)) +
geom_crossbar(width = 0.5, position = "dodge") +
#coord_flip() +
scale_x_discrete(breaks=selectedData$label, labels=as.vector(selectedData$model_labels)) +
xlab('model') +
ylab(g) +
ggtitle(g)
print(p)
}
# family-wise hypothesis test
source('familywiseHypoTest.R')
foldResults <- cvResults$foldResults
# sig_cv <- familywiseHypoTest(iterationResults=foldResults, accuracy_metrics, model_names)
# head(sig_cv)
sig_bs <- familywiseHypoTest(iterationResults=iterResults, accuracy_metrics, model_names)
head(sig_bs)
