---
title: "Transaction Weight Calibration Visualized"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("transaction_based_model.R")
source("size_metric_based_models.R")
source("utils/data_selection.R")
source("accuracy_confidence_evaluation.R")
source("utils/feature_selection.R")
library(jsonlite)
library(reshape)
library(tidyverse)
library(fitdistrplus)
library(egg)
library(gridExtra)
library(plyr)
require(MASS)

```
Combined Data Effort Values
```{r descriptive statistics, fig.width=5,fig.height=2.5}
dataSet <- selectData("modelEvaluations-1-3.csv")

modelData <- dataSet[["modelData"]]
combined <- dataSet[["combined"]]
effort <- dataSet[["effort"]]

```

#load the comparative models. Each model for comparison should include two functions for evaluateion:
#1. model_train(dataset)
#2. model_predict(dataset)

```{r swtiii, warning = FALSE}

#train the size metric based models
models <- size_metric_models()

#load the machine learning based models
  
```
comparison between SWTIII, UCP, COCOMO, a-priori COCOMO using cross-validation
```{r modelPlot, warning = FALSE, fig.width=5,fig.height=4}
#df <- read.csv("modelEvaluations-8-16-3.csv")

benchmarkResults <- modelBenchmark(models, dataset)

cvResults <-benchmarkResults[["cvResults"]]
print(cvResults)

```
